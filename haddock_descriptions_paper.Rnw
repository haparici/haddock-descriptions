\documentclass[letterpaper, 12pt]{article}
%\usepackage{liatex85}
\usepackage{etex}
\usepackage{geometry}                % See geometry.pdf to learn the layout options. There are lots.
\geometry{letterpaper}                   % ... or a4paper or a5paper or ... 
\usepackage{amsmath,amsfonts, amssymb,latexsym, mathtools,mathrsfs, fancyhdr,theorem,  pifont, setspace, verbatim,  qtree, lscape, tipa,  hyperref,verbatimbox, wasysym, natbib,soul, minibox, lipsum, amssymb, color, multirow, multicol, soul,geometry,graphicx, wrapfig,gb4e,booktabs,stmaryrd,makecell}
\usepackage[T1]{fontenc}
\usepackage{times}
%\usepackage[backend=bibtex, sorting=none]{biblatex}
\geometry{hmargin={1in,1in},vmargin={1in,1in}}

\definecolor{Red}{RGB}{255,0,0}
\newcommand{\red}[1]{\textcolor{Red}{#1}}
\newcommand{\ha}[1]{\textcolor{Red}{[ha: #1]}} 


 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
 %%%% Some math symbols used in the text
 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
 % Format 


\def\>{\rangle}
\def\<{\langle}

\def\true{1}
\def\given{\,|\,}

\def\valueof#1{\llbracket #1\rrbracket}


\def\ol#1{\textit{#1}}

\def\valueof#1{\ensuremath{\llbracket #1\rrbracket}}


\title{Haddock Descriptions and Relative Readings of Relative (Comparative) Adjectives}
\author{Helena, Roger, Liz}


\begin{document}

\maketitle

<<Setup, include=FALSE>>=

# Import libraries

#General

require(knitr)
#library(devtools)

#Stats
require(lmerTest)
#devtools::install_github("paul-buerkner/brms")
require("rstan") 
require(brms)
require(broom)
require(lmerTest)

#Plotting
#require(Rmisc)

require(ggplot2)
require(RColorBrewer)
#require(tidyboot)
#require(dplyr)

#Running models
require(ggm)
require(ggpubr)
require(rlist)
require(RJSONIO)
require("rwebppl")
#to install rwebppl
#install.packages("devtools")
#devtools::install_github("mhtess/rwebppl")

# Global settings for chunks
opts_chunk$set(echo = F, message = F, warning = F, cache=T)
#fig.path <- "../../" in case we end up needing it

#Repo
#https://github.com/haparici/haddock-descriptions

require(tidyboot)
require(dplyr)
@

<<Model_Parameters_Variables, echo=FALSE, cache=TRUE,warning=FALSE, message=FALSE, include=FALSE>>=

## Visuals Master ##
refs_json <- '[
  {"Animal": "rabbit", "Container": "bag", "Size": 1}
  , {"Animal": "rabbit", "Container": "bag", "Size": 2}
  , {"Animal": "frog", "Container": "bag", "Size": 3}
  , {"Animal": "frog", "Container": "box", "Size": 1}
  , {"Animal": "rabbit", "Container": "box", "Size": 2}
  , {"Animal": "frog", "Container": "basket", "Size": 3}
  , {"Animal": "rabbit", "Container": "box", "Size": 1}
  , {"Animal": "frog", "Container": "bag", "Size": 1}
  ]'

refs <- fromJSON(refs_json)
refs <- do.call("rbind", refs)
refs <- data.frame(refs)

## Visual Logical Constructor ##
conds_idx <- list(
  c(TRUE, TRUE, TRUE, TRUE, TRUE, FALSE, FALSE, FALSE)
  , c(TRUE, TRUE, FALSE, TRUE, TRUE, TRUE, FALSE, FALSE)
  , c(TRUE, TRUE, TRUE, FALSE, TRUE, FALSE, TRUE, FALSE)
  , c(FALSE, TRUE, TRUE, TRUE, TRUE, FALSE, FALSE, TRUE) #context4
)

get_visuals <- function(refs, conds_idx, i){
  
  cond_idx <- unlist(conds_idx[i])
  visual <- refs[cond_idx, ]
  
  return(visual)
  
}

## Descriptions ##
modifiers <- c('smaller', 'small', 'big', 'bigger', 'none')
#modifiers <- c('small', 'big', 'none')
get_descriptions <- function(visual, modifiers) {
  
  visual_unique <- unique(visual[, c("Animal", "Container")])
  
  descs <- list()
  for (ref in 1:nrow(visual_unique)) {
    for (mod in modifiers) {
      animal <- visual_unique[ref, "Animal"]
      container <- visual_unique[ref, "Container"]
      desc = list(animal, mod, container)
      descs <- list.append(descs, unlist(desc))
    }
  }
  desc <- list("none", "none", "none")
  descs <- list.append(descs, unlist(desc))
  return(descs)
}

get_costs <- function(descs) {
  
  costs <- list()
  columns <- list()
  
  for (i in 1:length(descs)) {
    
    desc <- unlist(descs[i])
    desc_str <- paste(desc[1], desc[2], desc[3])
    adjective <- desc[2]
    tail <- substr(adjective, nchar(adjective) - 1, nchar(adjective))
    
    if (tail == "er") {
      
      cost <- 1.5
      
      
    } else if (adjective %in% c("small", "big")) {
      
      cost <- 1
      
    } else if (adjective == "none") {
      
      cost <- 0.5
      
    } else {
      
      cost <- 0
      
    }
    costs <- list.append(costs, cost)
    columns <- list.append(columns, desc_str)
  }
  costs <- data.frame(costs)
  colnames(costs) <- unlist(columns)
  
  return(costs)
}

    
##Random Variables##

pos<-list(c("rabbit", "big", "bag"), c("rabbit", "big", "box"))
cmp<-list(c("rabbit", "bigger", "bag"), c("rabbit", "bigger", "box"))

randomVariables<-list(pos,cmp)
#randomVariables<-list(pos)
#randomVariables<-list(cmp)

execute_model <- function(randomVariable, cond, model, context, defArt, package, gamma, costCoefficient,cmpHighScopeConstrualProb,posHighScopeConstrualProb,allowUninformativeThresholds,pragListenerLevel) {
  
  # Model
  visuals <- get_visuals(refs, conds_idx, cond)
  descs <- get_descriptions(visuals, modifiers)
  costs <- get_costs(descs)
  
  model_data <- list(randomVariable, visuals, descs, costs, context, defArt, gamma, costCoefficient,cmpHighScopeConstrualProb,posHighScopeConstrualProb,allowUninformativeThresholds,pragListenerLevel)
  
  model <- webppl(program_file=model, 
                  data = model_data, 
                  data_var = "model_data", 
                  package=package)
  
  return(model)
  
}



@


<<Model_Main, echo=FALSE, cache=TRUE, warning=FALSE, message=FALSE, include=FALSE>>=

## Main ##
# Calling Parameters 

conds <- c(1, 2, 3, 4)
#conds <- c(4)
contexts <- c("cco","no-cc")
defArtMeanings <- c("bumford", "standard")
pragListenerLevels <- c(1, 2)
models <- c("haddock_model.wppl") #,"haddock_model_pragmaticListener2.wppl")
#gamma is probability that any given referent will be included in the context
gamma <- .5
#higher cost coefficient increases informativity effect but speaker always prefers silence for higher values of costCoefficient 
costCoefficient <- 1
cmpHighScopeConstrualProb <- 0.9
posHighScopeConstrualProb <- 0
cmpHighScopeConstrualProbs <- c(0,0.5,0.9,1)
posHighScopeConstrualProbs <- c(0,0.5,0.9,1)

allowUninformativeThresholds <- "disallow"
allowUninformativeThresholdLevels <- c("allow","disallow","lastresort")


#randomVariable, cond, model, context, defArt, package, gamma, costCoefficient,highScopeConstrualProb,pragListenerLevel

test_result <- execute_model(cmp, 
                             4, #cond
                             "haddock_model.wppl",
                             "cc",
                             "standard",
                             ".", #package
                             gamma,
                             costCoefficient,
                             cmpHighScopeConstrualProb,
                             posHighScopeConstrualProb,
                             allowUninformativeThresholds,
                             2) #pragListenerLevel

test_result 

#Do we want to calculate the model results?
recalculate_model_results <- FALSE
#Or read them from a file?
read_model_results <- TRUE

# Execute Model

results <- data.frame()
if (recalculate_model_results) {
  for(allowUninformativeThresholds in allowUninformativeThresholdLevels) {
    for (cmpHighScopeConstrualProb in cmpHighScopeConstrualProbs) {
      for(posHighScopeConstrualProb in posHighScopeConstrualProbs) {
        for(pragListenerLevel in pragListenerLevels) {
          for(defArtMeaning in defArtMeanings) { 
            for (context in contexts) {
              for (randomVariable in randomVariables) {
                for (cond in conds) {
                  for (model in models) {
                    
                    result <- execute_model(randomVariable, 
                                            cond, 
                                            model, 
                                            context,
                                            defArtMeaning,
                                            ".",
                                            gamma,
                                            costCoefficient,
                                            cmpHighScopeConstrualProb,
                                            posHighScopeConstrualProb,
                                            allowUninformativeThresholds,
                                            pragListenerLevel) 
                    
                    if (!(is.null(result))) {
                      
                      result$Adjective <- randomVariable[[1]][2]
                      result$defArtMeaning <- defArtMeaning
                      result$Context <- context
                      result$Condition <- cond
                      result$Model <- model
                      result$ListenerLevel <- pragListenerLevel
                      result$cmpHighScopeConstrualProb <- cmpHighScopeConstrualProb
                      result$posHighScopeConstrualProb <- posHighScopeConstrualProb
                      result$allowUninformativeThresholds <- allowUninformativeThresholds
                      results <- rbind(results, result)
                      
                    }
                    #print(paste("Processing adjective"
                    #      , randomVariable[[1]][2]
                    #      , "for context"
                    #      , context
                    #      , "for defArtMeaning"
                    #      , defArtMeaning
                    #      , "for condition"
                    #      , cond
                    #      , "with model"
                    #      , model))
                  }
                }
              }
            }
          }
        }
      }
    }
  }
  
  colnames(results) <- c(
    "Animal",
    "ContainerType",
    "Size",
    "Probability",
    "Adjective",
    "DefArtMeaning",
    "Context",
    "Condition",
    "Model",
    "ListenerLevel",
    "cmpHighScopeConstrualProb",
    "posHighScopeConstrualProb",
    "allowUninformativeThresholds")
  
  results$Container <- paste0(results$ContainerType,results$Size)
  View(results)

  #write results to file
  
  write.csv(results, "model-outputs.csv")

}

#save a copy for posterity
#today <- Sys.Date()
#write.csv(results, paste0("model-outputs-",today,".csv"))


if (read_model_results) {
  results <- read.csv("model-outputs.csv")
}


@

\begin{abstract}
Definite articles, superlative adjectives, and positive adjectives are all interpreted relative to a given class of objects---a `comparison class', broadly construed. 
This article investigates whether restrictions on the comparison class for a definite article are always inherited by other comparison class-sensitive modifiers in the same noun phrase. For both definite descriptions and superlative adjectives, the comparison class can be restricted by surrounding lexical material; for example; {\em the rabbit in the hat} can mean {\em the rabbit in the hat \underline{containing a rabbit}}, and {\em the rabbit in the biggest hat} can mean {\em the rabbit in the biggest hat \underline{containing a rabbit}}. When there are multiple comparison class-sensitive items within a single noun phrase, are the comparison classes subject to the same restrictions? With superlative adjectives like {\em biggest}, a mismatch would not be truth-conditionally distinguishable from a match. But with positive and comparative adjectives like {\em big/ger}, mismatches are possible in principle to detect because unlike superlative adjectives, positive and comparative adjectives do not entail uniqueness. We argue on the basis of both distributional and experimental evidence that prenominal positive adjectives do not inherit the restrictions on the definite article for CC calculation. We find furthermore that comparative adjectives not only have the kinds of relative readings that superlatives have, but that these types of readings are strongly preferred by listeners in our experiments.


%can have both readings, both scopes are possible. Finally, we use computational modelling to argue that these epositive adjectives xxx in that thresholds are context-sensitive. Emerges a link between lexically context-sensitive predicates and their ability to take scope.

%and that their CC is always computed w.r.t. their syntactic NP complement, a fact that we take to indicate that positive adjectives cannot take high scope.

%We find furthermore that comparative adjectives not only have the kinds of relative readings that superlatives have, but that these types of readings are strongly preferred by listeners in our experiments.
\end{abstract}

\section{\label{intro}Introduction}


%Are ``mixed readings'' possible, where the definite scopes high and the adjective scopes low? 
%Research question: Does any modifier that uses a comparison class use the same comparison class that the definite article uses, or can there be mismatches?


Suppose there are three bags, two rabbits, a frog, and a calculator on a table before you. 
One of the rabbits is in one of the bags, and the other two bags contain the frog and the calculator, respectively.
You are instructed to point to {\em the bag}. 
``Which bag?'' you might object in puzzlement; there are three.
Asked to point to {\em the rabbit in the bag}, however, you would confidently pick out the rabbit in {\em the bag that contains a rabbit}. 
Such nested definite descriptions, in which the inner definite seems to lose its uniqueness requirement, are known as {\em Haddock descriptions} \citep{haddock:1987}.

As \citet{bumford:2017} points out, Haddock descriptions have much in common with so-called {\em relative readings} of superlatives. In \ref{superlative}, for example, {\em the biggest bag} can refer either to the biggest of all bags (absolute reading), or the biggest of the bags that contain rabbits (relative reading). 

\begin{exe}
\ex\label{superlative} the rabbit in the biggest bag.
\end{exe}


Both Haddock readings of embedded definite descriptions and relative readings of superlatives involve an apparent enrichment of the content in the lower noun phrase. And in both cases, the enrichment of the content can be viewed as a scope-based phenomenon.

%The absolute reading obtains when the superlative adjective is interpreted in its base position. Under this reading, sentence (\ref{superlative}) is true iff the context contains a unique rabbit that is in the unique biggest bag. 
%On the other hand, the relative reading arises when the superlative adjective scopes out above the higher NP. In this case, the sentence is true as long as there is a unique rabbit that is inside the biggest rabbit-containing bag, even if the context contains bigger rabbitless bags. Put it differently, the scope of the superlative determines the Comparison Class (CC) against which the adjective is interpreted: low scope, CC of bags. High scole, CC of rabbit-containing bags. Comparison Class calculation tracks scope of the definite.\footnote{This depends on the assumption that the scope of the definite marks the upper bound.}


According to scope-based theories of superlatives \citep{szabolcsi:1978,heim:1999,bumford:2017}, an absolute reading obtains when the superlative adjective is interpreted in its base position,  
while a relative reading arises when the superlative adjective scopes out above the higher NP. 
In this case, the description can refer as long as there is a unique rabbit that is inside the biggest rabbit-containing bag, even if the context contains bigger rabbitless bags. 
To put it differently, the scope of the superlative determines the comparison class (CC) against which the adjective is interpreted. 
In a nutshell: low scope, CC of bags; high scope, CC of rabbit-containing bags.

According to \citet{bumford:2017}, the definite article can also take scope. In a case like {\em the rabbit in the bag}, the lower {\em the} can either be interpreted (i) {\em in situ}, in which case it requires uniqueness (within the relevant situation) with respect to the predicate `bag', or (ii) with scope over {\em rabbit}, in which case it requires uniqueness with respect to the predicate `rabbit-containing bag'. For the sake of discussion, let us stretch the term `comparison class' to describe this class relative to which the uniqueness is determined, for the definite article.

For a case like {\em the rabbit in the biggest bag}, Bumford's system allows a reading on which both the definite article and the superlative take scope over {\em rabbit}. When both are interpreted with high scope, it is as if {\em bag} means `rabbit-containing bag'. Would it be possible for one to take high scope while the other remains {\em in situ}? In principle, nothing in Bumford's theory prevents this, but such a situation would be difficult if not impossible to detect. If the definite article took high scope while the superlative remained {\em in situ}, then uniqueness with respect to the embedded NP would be implied by the superlative description, so the definite article might as well be in the lower position. A reading on which the superlative took high scope while the definite remained {\em in situ} would yield a uniqueness requirement that is much stricter than the one imposed by other readings, so it would remain hidden.

With positive-form gradable adjectives, on the other hand, it would be possible to detect a mismatch in scope between the definite article and the modifier.
Positive-form adjectives are thought to involve a contextually-given threshold, whose value is constrained by a contextually salient comparison class. The comparison class is typically represented by the head noun; thus a {\em big bag} is big {\em for a bag}. But in principle, {\em the rabbit in the big bag} could be interpreted as {\em the rabbit in the big \underline{rabbit-containing} bag}, by analogy to definite descriptions and superlatives. This is the kind of reading that would arise if the adjective took high scope in the way that superlatives do. On a high-scope reading, the range of viable thresholds would be constrained more tightly by the smaller comparison class (bags that contain rabbits).



This paper investigates the degree to which high scope readings are available for positive adjectives, using both traditional distributional evidence (Section \ref{sec:armchair}) and experimental evidence (Section \ref{sec:exp}). Both sources of evidence suggest that positive form adjectives do not have high scope readings. Or, to put it in terms that do not depend on a scope-based analysis of Haddock descriptions or relative readings of superlatives, constraints on the comparison class for definite articles are not inherited as constraints on the comparison class for gradable adjectives in the same noun phrase.


\section{Scope and Comparison Classes}
\subsection{Superlative}

% \begin{figure}
%   \begin{tabular}{ | l| l | l | l | l | l | l | }
%     \hline
%    \multirow{2}{*}{Reading} & \multirow{2}{*}{Configuration} & \multicolumn{3}{l|}{Scope-taking operators}  & \multirow{2}{*}{Paraphrase} &       \multirow{2}{*}{Relative reading}\\     \cline{3-5}
%      & & Det_x & Det_y &  Adj  & \\ \hline
%      a & det_x(det_y(Adj(N1_x N2_y)))  & high & high & high & \makecell{The unique rabbit in \\the biggest rabbit-containing        bag.} & allowed\\   \hline
%      b & det_x(det_y(N1_x Adj N2_y))  & high & high & low & \makecell{The unique rabbit in \\the rabbit-containing bag\\which      is also the biggest bag.}& disallowed\\ \hline
%      c & det_x(Adj((N1_x det_y N2_y)))  & high & low & high & \makecell{The unique rabbit in \\the biggest rabbit-containing        bag\\which is also the unique bag.}& disallowed\\ \hline
%      d & det_x(N1_x det_y(Adj N2_y))  & high & low & low & \makecell{The unique rabbit in \\the unique biggest bag.} &              disallowed\\ \hline
%   \end{tabular}
%   \caption{Possible readings for superlative adjective.}
% \end{figure}


REadings b and c are the ones that allow inverse scope, but theu are indistinguishable from a ahd d. A and b allow for relative readings. B and C do not. On the surface, looks like they track each other. When one is met, the other is met as well.

\begin{exe}
\ex $\valueof{A}=\lambda \theta_A\lambda x[\mu_A(x) > \theta_A]$
\end{exe}


When the adjective combines with other degree morphology we get: This meaning is by Heim (1999). 
\begin{exe}
\ex $\valueof{-est}=  \lambda C\lambda A\lambda x\exists d[A(d)(x) \wedge \forall y \in C[y \neq x \rightarrow \sim A(d)(y)]]$\\
     Presupposes that x $\in$ C and that all other members in C have some degree of the adjectival property.
\end{exe}

Which gives you the following:

\begin{exe}
\ex\label{a-est} $\valueof{\textit{A-est_C}}= \lambda x\exists d[\mu_A(x) > d \wedge \forall y \in C[y \neq x \rightarrow \sim\mu_A(y) > d]]$
\end{exe}


\subsection{Positive Form}


% \begin{figure}
%   \begin{tabular}{ | l| l | l | l | l | l | l | }
%     \hline
%    \multirow{2}{*}{Reading} & \multirow{2}{*}{Configuration} & \multicolumn{3}{l|}{Scope-taking operators}  & \multirow{2}{*}{Paraphrase} &       \multirow{2}{*}{Relative reading}\\     \cline{3-5}
%      & & Det_x & Det_y &  Adj  & \\ \hline
%      a & det_x(det_y(Adj(N1_x N2_y)))  & high & high & high & \makecell{The unique rabbit in \\the big rabbit-containing        bag.} & allowed\\   \hline
%      b & det_x(det_y(N1_x Adj N2_y))  & high & high & low & \makecell{The unique rabbit in \\the rabbit-containing bag\\which      is also a big bag.}& \red{allowed}\\ \hline
%      c & det_x(Adj((N1_x det_y N2_y)))  & high & low & high & \makecell{The unique rabbit in \\a big rabbit-containing        bag\\which is also the unique bag.}& disallowed\\ \hline
%      d & det_x(N1_x det_y(Adj N2_y))  & high & low & low & \makecell{The unique rabbit in \\the unique big bag.} &              disallowed\\ \hline
%   \end{tabular}
%   \caption{Possible readings for positive form adjective.}
% \end{figure}

Because the positive form adjective does not require uniqueness, relative readings are allowed in more places.

\begin{exe}
\ex $\valueof{A}=\lambda \theta_A\lambda x[\mu_A(x) > \theta_A]$
\end{exe}
\begin{exe}
\ex $\valueof{POS}= \lambda A\lambda x[A(s_A) > s_A]$
\end{exe}


\begin{exe}
\ex $\valueof{POS A}=\lambda x[\mu_A(x) > s_A]$
\end{exe}

\subsection{Comparative}

\section{Distributional evidence}
\label{sec:armchair}

Superlatives are known to exhibit an ambiguity between so-called `absolute' and `relative' readings. In this section, we argue that comparatives have the same kinds of relative readings that superlatives have, and that positive adjectives do not. 


\citet{szabolcsi:1986} pointed ou that superlatives obviate definiteness effects on focus-sensitive readings. Thus while \ref{def-effect} is degraded, \ref{sup-def-effect} is much less so. Example \ref{cmp-def-effect} shows that comparatives obviate definiteness effects as well. However, positive form adjectives do not, as shown in \ref{pos-def-effect}.

\begin{exe}
\ex
\begin{xlist}
\ex *Bernie has the campaign chairman.\label{def-effect}
\ex Bernie has the most enthusiastic campaign chairman.\label{sup-def-effect}
\ex Bernie has the more enthusiastic campaign chairman.\label{cmp-def-effect}
\ex Pointing at two campaign chairmans having a conversation. \\*Bernie has the enthusiastic campaign chairman.\label{pos-def-effect}
\end{xlist}
\end{exe}

So comparatives pattern like superlatives on relative readings with respect to this diagnostic, and positive form adjectives do not.

As \citet{bumford:2017} discusses, relative readings of superlatives are blocked by possessives, and similar effect can be observed with comparatives, but not positive form adjectives. \ref{noposs-sup} is asking for the person who has read a longer play by Shakespeare than anyone else under consideration, while \ref{poss-sup} is asking who has read the play by Shakespeare that is longer than any other play by Shakespeare, namely Hamlet.





\begin{exe}
\ex
\begin{xlist}
\ex Who has read the longest play by Shakespeare?
$\not\equiv$ Who has read Hamlet?\label{noposs-sup}
\ex Who has read Shakespeare's longest play?\\
$\equiv$ Who has read Hamlet?\label{poss-sup}
\end{xlist}
\end{exe}

Similarly, in \ref{noposs-cmp}, without a possessive, the question concerns which of two individuals read a longer play by Shakespeare than the other; the comparison is among readers. On the other hand, in \ref{poss-cmp}, {\em Shakespeare's longer play} acts as a referring expression, presuming that Shakespeare only wrote two plays. Again, we see that possessives prevent relative readings visible elsewhere from arising.



%\begin{exe}
%\ex $\valueof{-er}=  \lambda A \lambda P\lambda x[\partial(P(x)) \wedge A(d)(x)>A(d)(\iota y[P(y) \wedge x \neq y])]$
%\end{exe}



%The context fixes a granularity for each dimension, which expands equivalence classes of (plural) individuals along the dimension the corarse it is.
%Degrees at the wrong granularity do not exist for the purposes of quantification
%For a plurality X, G(X) is defined if and only if for all z and x' that are atomic sub-individuals of X, G(x)(d) = G(x').
%Do we need pluralities at all?

\begin{exe}
\ex
\begin{xlist}
\ex Who has read the longer play by Shakespeare?\label{noposs-cmp}
\ex Who has read Shakespeare's longer play?\\
$\leadsto$ Shakespeare wrote two plays\label{poss-cmp}
\end{xlist}
\end{exe}

In contrast, according to the native speaker intuitions of the English speakers we have consulted, we do not see a parallel effect with positive adjectives. Both \ref{noposs-pos} and \ref{poss-pos} imply that there was exactly one long play written by Shakespeare. 



%The comparative requires that there be only two objects satisfying P, assuming P can take plural individuals. Binary comparison. Unique individual that constitutes a standard of comparison. And states that there is another such invidual.\footnote{On plural standards of comparison? Multiple ways of constructing degree. In such case uniqueness violation of iota? Reminiscent of cases with quantification in the than clause: my car is faster than every cars. Distributive or collective reading? Gregs paper, it discusses whether these predications resist collective interpretation. Distributive interpretation predicts superlative-like interpretations, but the harder it is to determine the degree of the standard, the less felicitous the comparative is} As with the superlative, we predict the following available readings.



\begin{exe}
\ex
\begin{xlist}
\ex\label{noposs-pos} Who has read the long play by Shakespeare?
\ex\label{poss-pos} Who has read Shakespeare's long play?
\end{xlist}
\end{exe}

If there were a relative (high-scope) reading for \ref{noposs-pos}, it would be much like the relative reading of \ref{noposs-sup}: Of the plays by Shakespeare that have been read by someone in the context, who has read the long one? But \ref{noposs-pos} does not seem to have such a reading.


\citet{bhatt:1999,bhatt:2006} also points out that superlatives are among a restricted set of modifiers that license non-modal infinitival relative clauses, along with ordinals and exclusives. As it turns out, comparatives are like superlatives in this respect, but positive-form adjectives are not.






%Here we ask the question of whether unmodified and comparative relative adjectives give rise to relative readings (\ref{poscmp}).
%Such relative readings could be detected if externally-imposed constraints on a referent constrain the interpretation of gradable adjectives characterizing that referent. 
%Put it differently, relative readings arise if both the comparative and the positve form adjectives can take high scope above the higher NP.
%For instance, on its relative reading (\ref{cmp}) is true iff the context contains exactly two rabbits in bags and exactly two rabbit-containing bags, as long as such bags differ in size.
%The case of positive form gradable adjectives is different, as these predicates have been argued to be context-sensitive such that their interpretation involves resolving an adjectival threshold with respect to a contextually salient Comparison Class determined by the head noun. 

%A relative reading for a positive form relative adjective like (\ref{pos}) arises if further external constraints beyond the meaning of the head-noun (e.g.\ containing a rabbit) constrain the comparison class used for the evaluation of the adjective.
%More specifically, the relative reading of (\ref{pos}) is true iff there is a unique rabbit that is in the unique rabbit-containing bag that is big in the context.


%Haddock proposed that the problem posed by these nested definites disappears if  semantic interpretation proceeds incrementally, i.e., from left to right. 
%In this view, identifying the referent of a definite description is conceived as a constraint satisfaction task, in which constraints are added incrementally as comprehension proceeds.
%As new information about the referent comes in, the listener narrows down the set of potential referents to those individuals that are compatible with the linguistic information.  
%The description is felicitous if there is only one individual who satisfies all the necessary constraints, including those imposed internally to the noun phrase (e.g.\ being a hat), and those imposed externally (e.g.\ containing a rabbit).

%In the example we started with, this would be the case if there is only one $y$ such that (i) $x$ is a rabbit; (ii) $y$ is a bag; and (iii) $x$ is in $y$.
%One can readily see that in our original example incremental interpretation ensures that these constraints are met; by the time the description is fully interpreted, the context is  circumscribed to rabbit-containing bags, thus satisfying the uniqueness requirement of the nested definite.


%Solutions of the sort proposed by Haddock are compatible with psycholinguistic findings of online language comprehension during reference resolution tasks. In seminal work using the Visual World eye-tracking paradigm, Eberhard and colleagues (1995) found that listeners incrementally constrain the set of potential referents when interpreting descriptions of the form {\em the starred yellow square} as new linguistic input unfolds over time.
%Other references that we might want to add eventially  Altmann \& Kamide (1999); Kako \& Trueswell (2000). 


%Furthermore, it has also been shown that listeners rapidly integrate other sources of information above and beyond linguistic information. 
%For instance, it has been noted that adjectivally modified definite descriptions such as {\em the tall glass} give rise to inferences about contrast such that the prenominal adjective is expected to disambiguate between two objects of the same category that differ only with respect to the degree to which they bear the adjectival property (e.g., a tall and a short glass). 
%Put in Gricean terms, prenominal adjectives give rise to informativity expectations.
%In a Visual World eye-tracking study, Sedivy et al. (1999) showed that listeners use contextual information about contrast predictively to guide reference resolution during the processing of adjectivally modified Noun Phrases. 
%Their results demonstrated that listeners were faster at identifying the referent of an auditorily presented modified NP such as {\em the tall glass} when the visual context supported a contrastive interpretation of the adjective (i.e., when the visual context contained a contrast set formed by a tall and a short glass) compared to contexts where the adjective was used redundantly (i.e., contexts that only contained a tall glass). 
%Importantly, participants were able to identify the referent of the definite description during the adjective window, before any information about the head-noun was available to them.
%This was the case despite the fact that the visual context also contained a competitor object that could also be described by the prenominal adjective (e.g. a tall pitcher).
%The fact that participants were able to use information about contrast to identify the referent of the description at a point where the linguistic input was still ambiguous between two objects (i.e. the tall glass and the tall pitcher) demonstrates that listeners rapidly integrate both linguistic and pragmatic information, thus supporting the view that language processing proceeds incrementally.


%Without being fully explicit about the mechanisms, \citet{vaneijck:1993} offers a variation on Haddock's idea in terms of dynamic semantics: The inner noun phrase is associated with a discourse referent, upon which constraints are added sequentially in the manner that dynamic meanings update contexts. 
%\citet{bumford:2017} offers a fully explicit dynamic semantic account. 
%Bumford proposes that the uniqueness requirement of the inner definite of a Haddock definite can be satisfied through a scope-taking mechanism that lets the uniqueness requirement of the definite article take scope above the higher noun (i.e. {\em rabbit} in our original example), thus ensuring that uniqueness is only checked with respect to rabbits that are inside bags. 
%In that scope position, what the uniqueness requirement demands is that there be no more than one {\em bag containing a rabbit}, even if there is more than one {\em bag}. Bumford's dynamic semantic account does not rely on incremental processing, but it does implement Haddock's idea that uniqueness is checked relative to a conglomeration of internal constraints (being a bag) and external constraints (containing a rabbit).

%A possible challenge to a scope-based account such as Bumford's can be found in facts pertaining to the interpretation of unembedded definites, which can also involve a flexible conception of uniqueness. 
%In an eye-tracking study, \citeauthor{chambers+al:2002} find that given the instruction {\em Put the cube inside the can}, listeners easily identify the referent of {\em the can} as the one that is large enough to hold the cube in question, even if there are multiple cans in the display.
%This suggests that entities that meet the description but cannot possibly serve as the intended referent are excluded from the count. 
%These experimental findings also bolster the observation by \citet{stone+webber:1998} that in the kind of scenario we began with, it would be felicitous to utter either {\em Remove the rabbit from the bag} or {\em Bill put the rabbit in the bag}, where the PP containing the second definite is a syntactic argument of the verb.

%Under all of these views, it is not only the descriptive content of the noun phrase that uniqueness is determined relative to; it is the sum of all of the constraints imposed on the referent, including those imposed externally. 

%A view that is consistent with these kinds of uses is offered by \citet{muhlstein+al:2015}.
%They propose that listeners reason probabilistically about the context relative to which a definite description should be interpreted. 
%Under this proposal, the task of the listener, upon hearing a definite description, is to infer the referent of the description {\em and} the (partition of the) context that satisfies the uniqueness requirement of the definite article, relative to the descriptive content of the noun phrase.

%Although uniqueness is only checked relative to the description-internal constraints, the description-external constraints play a role in restricting the context.


%This solution differs from the semantic account of Haddock Descriptions put forth by Bumford in that uniqueness is independently checked for each definite article {\em in situ}. 
%This account also differentiates itself from Haddock's proposal in that context-restriction effects are achieved without assuming incremental interpretation.

%Putting this idea of context flexibility together with incremental processing, we might imagine a view on which context narrowing occurs incrementally, so that referents that are not compatible with the linguistic input are automatically eliminated from the context. For example, after hearing {\em the rabbit in the}, all referents that do not contain a rabbit are eliminated from the current context.\footnote{A question arises then as to how something like {\em the rabbit in the hat with the bow on top} would be interpreted. The bow would have been eliminated from the context, if it didn't contain a rabbit. To handle such things, it would seem necessary to assume a `resetting' of the context for every new noun phrase.}




%The interpretation of gradable adjectives is usually assumed to depend on a contextually salient CC that is provided by the head noun. 
%Split-scope theories of Haddock Descriptions predict that the positive form adjective, just like the comparative, could be interpreted low or high.
%If prenominal adjectives are interpreted with respect to a Comparison Class that is determined by the material in the scope of the adjective.



\begin{exe}
\ex
\begin{xlist}
\ex John gave Mary the most expensive telescope\label{sup-infin}
\ex ... to be built in the 9th century.\label{sup-infin-cont}
\end{xlist}
\ex
\begin{xlist}
\ex John gave Mary the more expensive telescope\label{cmp-infin}
\ex ... to be built in the 9th century.\label{cmp-infin-cont}
\end{xlist}
\ex
\begin{xlist}
\ex John gave Mary the long telescope
\ex ... *to be built in the 9th century.
\end{xlist}
\end{exe}

Interestingly, the continuation in \ref{sup-infin-cont} restricts the range of available readings for \ref{sup-infin}. In its absence, but only then, \ref{sup-infin} can mean that John gave Mary a more expensive telescope than he gave anyone else. Comparatives are subject to the same effect: The continuation in \ref{cmp-infin-cont} eliminates a reading for \ref{cmp-infin} where Mary is compared to an alterantive.

Further evidence comes from ambiguities involving finite relative clauses.  \citet{bhatt:2002} observed that
\ref{tolstoy:longest} is ambiguous betweeen what he calls `high' and `low' readings.

\begin{exe}
\ex the longest book that John said Tolstoy had written\label{tolstoy:longest}\\
High reading: of the books John said Tolstoy wrote, the longest\\
Low reading: the book John said was longest among the ones written by Tolstoy.
%\begin{xlist}
%\ex the first book that John said Tolstoy had written\label{tolstoy:first}
%%\b. the only book that John said Tolstoy had written
%\ex 
%\end{xlist}
\end{exe}

Bhatt takes `low' readings as evidence in favor of a view of relative clauses on which the head noun (here: {\em book}) originates within the relative clause. This issue is not of concern here; we note only that the comparative version \ref{tolstoy:longer} is ambiguous in an analogous way, but the version with the positive adjective \ref{tolstoy:long} is not:

\begin{exe}
\ex the longer book that John said Tolstoy had written\label{tolstoy:longer}\\
High reading: of the books John said Tolstoy wrote, the longer\\
Low reading: the book John said was longer among the ones written by Tolstoy.
\ex the long book that John said Tolstoy had written\\
High reading: of the books John said Tolstoy wrote, the long one\\
*Low reading: the book John said was long among the ones written by Tolstoy.\label{tolstoy:long}
\end{exe}

%Here is a random citation that somebody must have written down
%hoping that they would remember it.
%May someone one day remember what this was for.
%\citet{sleeman:2010}: `identificational focus' \citep{kiss:1998a}

Taken together, this distributional evidence suggests that positive adjectives are unlike comparative and superlative adjectives in that they lack so-called `relative readings'. In the following section, we present experimental evidence in further support of this conclusion.


\section{Two theories}

\subsection{Bumford}

\subsection{Muhlstein}

conclusion: one solution non-local uniqueness check vs. context coordination plus penalizing reference failure. Show this with unmodified Haddock Descriptions.


\subsection{The rabbit in the big bag}

Here we use adjectivally modified Haddock Descriptions to capitalize on the following intuition. 

Collect data. lower acceptability of the label is due to the fact that there is higher threshold uncertainty in the global context and only a subset of these thresholds result in a defined referent. This is excatly what's predicted by Bumford: two thresholds are possible but only one results in a defined description. Dispreference for 3 bags is ruled by threshold uncertainty. For Bumford dispreference results from context-coordination and reference failure.

On the other hand, the 

Show that each of these two theories predicts lower accetability in two different ways: Almost all potential for reference failure results from uniqueness check with threshold uncertainty almost not playing a role. The different ways in which a modified Haddock description can fail allows us to tease apart these two theories experimentally and understand what the right formulation of the uniqueness check ought to be and whether context coordination is needed. Different ways in which reference faiure comes about.


\section{The current experiment}
\label{sec:exp}

Dispreference for 3 vs. 2 results from different rates of reference failure resulting from threshold uncertainty + interaction with complex uniqueness requirement, whereas in the second theory it results from context coordication + vanilla uniqueness check.
The current experiment investigates, no intuitions about the quantitative differences made by these two xxxx. 3 vs two bags

\subsection{Design}

Participants heard auditory instructions while looking at visual displays consisting of five images arranged in a circle. In experimental trials, the auditory instruction consisted of a request of the form `{\em Click on the rabbit in the big} [{\em masked}]', where the second NP had been masked with quite static noise. 
Each display contained two possible referents compatible with the truncated description (e.g., the rabbit in the medium-sized bag and the rabbit in the medium-sized box in Figure \ref{displays}). 
Given this ambiguity, participants were instructed to click on the referent they believed was intended by the speaker.

By eliciting responses before the semantic integration of the inner noun takes place, we can tap into the question of how listeners' expectations are affected by the available linguistic information given the visual context.
More specifically, this task allows us to ask how threshold uncertainty, which we assume to be higher for those resolutions that are compatible with more adjectival thresholds, modulates the rates of target selection. 
This was achieved by manipulating the amount and seizes of the containers in the display that were compatible with either of the two possible continuations of the auditory instruction, i.e. bags vs. boxes in Figure \ref{displays}.
As seen in Figure \ref{displays}, only one of the two thresholds licensed by the visual display resulted in a defined description for the bag resolution.
%Because we are interested in teasing apart effects of reference failure driven by threshold uncertainty

%A fully disambiguated instruction would have settled once and for all what the referent is; the ambiguous instruction gives a window into the information conveyed to the listener by the modifying adjective.

%We need to explain how this works

\begin{figure}[h]
\centering
\begin{tabular}{ccc}
\textbf{Threshold Uncertainty}  & \textbf{Informativity Violation} & \textbf{Both} \\[.2em]
    \includegraphics[width=2in]{images/Context3.png} & 
    \includegraphics[width=2in]{images/Context2.png} &
    \includegraphics[width=2in]{images/Context1.png} \\
    \textbf{Scene 1} & \textbf{Scene 2} & \textbf{Scene 3}
\end{tabular}    
  \caption{Visual Displays tested in Experiment 1. Clicking on the audio button would launch an auditory instruction of the form, ``Click on the rabbit in the \textbf{big} [masked]''}
\label{displays}
\end{figure}

%The experimental manipulations targeted the content of the auditory instructions, as well as the features of the visual displays. 
%The first manipulated factor was the type of adjective used to modify the masked NP in the auditory instruction.
%This modifier always consisted of {\em big} in either its positive ({\em big}) or comparative form ({\em bigger}). 

%The experimental manipulations targetted two aspects of the visual displays. 
%First we manipulated the amount of thresholds that listeners could adopt to resolve the meaning of the adjective. 
%This competitor was not a possible referent of the global description, because it did not fit the first NP in the description (e.g., a frog inside a bag). 
Despite not being compatible with the global instruction, this referent acted as a competitor because the size of its container was always greater than the biggest rabbit-containing bag/box in the display.
Thus, the competitor's container was the most appropriate referent of the embedded definite description if interpreted in isolation (see Context 1, or leftmost panel, in Figure \ref{displays}). 

%We manipulated two visual properties of the displays. The experimental manipulations described above were tested through the three visual contexts exemplified in Figure \ref{displays}. 
%One dimension along which the displays varied was whether they contained a competitor involving the same container-type as one of the potential referents of the truncated description (i.e., a big bag or a big box).
%This competitor was not a possible referent of the global description, because it did not fit the first NP in the description (e.g., a frog inside a bag). 
%Despite not being compatible with the global instruction, this referent acted as a competitor because the size of its container was always greater than the biggest rabbit-containing bag/box in the display.
%Thus, the competitor's container was the most appropriate referent of the embedded definite description if interpreted in isolation (see Context 1, or leftmost panel, in Figure \ref{displays}). 

To understand the strength of the threshold uncertainty manipulation better, we also manipulated the informativity of the modified utterance for the box resolution.

The second visual manipulation was whether the smallest box/bag in the display also contained a rabbit in it (e.g., a rabbit vs. a frog in the smallest box. See Contexts 1-2 vs. 3 respectively in Figure \ref{displays}). 
This manipulation determined whether the use of the adjective in the auditory instruction was informative, i.e., whether the mention of the adjective was required for successful reference resolution. 
For instance, given Context 1 in Figure \ref{displays}, where the smallest box in the display contains a frog and the smallest bag contains a rabbit, the adjective in the instruction `{\em Click on the rabbit in the big} [masked]' is informative on the bag resolution, but superfluous on the box resolution, since in the latter case the shorter adjectiveless description `{\em Click on the rabbit in the} [masked]' would have sufficed to properly identify the referent in the medium box, but not the referent in the medium bag.


%COMPARATIVE?


\subsection{Materials}

\subsubsection{Visual Stimuli}

Our experiments involved 12 targets and 24 fillers. The target items consisted of two animate objects, such as a rabbit and a frog, paired in some way (in or with) three possible inanimate objects beginning with the same letter, such as a box, a bag, and a basket. These are listed in Table \ref{table:target}.

\begin{table}
\begin{tabular}{@{}lllllll@{}}
\toprule
itemnum & anim1       & anim2  & prep & inan1   & inan2      & inan3    \\ \midrule
1       & rabbit      & frog   & in   & box     & bag        & basket   \\
2       & frog        & bird   & in   & bathtub & bucket     & boat     \\
3       & cat         & bird   & in   & truck   & tree       & tower    \\
4       & boy         & girl   & with & pillow  & paintbrush & pen      \\
5       & lady        & man    & with & fan     & fish       & flower   \\
6       & girl        & man    & with & dog     & duck       & doll     \\
7       & man         & girl   & with & sock    & scarf      & sandwich \\
8       & bird        & rabbit & in   & can     & cup        & car      \\
9       & monkey      & frog   & with & glue    & grapes     & glasses  \\
10      & farmer      & lady   & with & cheese  & chair      & cherries \\
11      & policewoman & boy    & with & carrot  & cookie     & cake     \\
12      & horse       & cat    & with & ladder  & lizard     & lamp     \\ \bottomrule
\end{tabular}
\caption{Target items.}
\label{table:targets}
\end{table}

The filler items determined a series of five images along with an accompanying instruction. More than half of the fillers involved a word that was masked, but not all. The phrases used were the following:

\begin{quote}
the glasses\\
the green [masked]\\
the blue fish in the [masked]\\
the yellow [masked]\\
the gray [masked] in the car\\
the cheese\\
the tall [masked]\\
the tall tower with the [masked]\\
the cat with the tall [masked]\\
the tall [masked] with the man\\
the girl\\
the short [masked]\\
the short pencil with the [masked]\\
the dog with the short [masked]\\
the short [masked] with the glass\\
the car\\
the taller [masked]\\
the taller building with the [masked]\\
the car with the tall [masked]\\
the tall [masked] with the dog\\
the shorter [masked]\\
the short glass with the [masked]\\
the cat with the shorter [masked]\\
the shorter [masked] with the horse
\end{quote}
The visual displays contained appropriately contrasting and varied items, such as a cat with a big ladder, a cat with a small ladder, a cat with a big ladder, a girl with a big dog, a girl with a medium-sized dog, a man with a vase.

\subsubsection{Auditory Stimuli}

The auditory stimuli were recorded by a male speaker. Care was taken to ensure that speech rate, volume, and pitch were as consistent as possible both within and between targets and fillers.


\subsection{Participants}

We collected data from 242 native speakers of English through the crowd-sourcing platforms Amazon Mechanical Turk and Prolific.
Data from 11 participants was removed from data analysis due to a failure to pass attention checks, i.e., they did more than 5 mistakes in the filler trials.
Finally, we removed data from three participants who took the experiment twice, resulting in a total of 225 participants.

\subsection{Predictions}

The goal of our experiment was to assess listeners' expectations as to whether positive and comparative form adjectives would give rise to high-scope readings when these modifiers appear in the embedded NP of a Haddock description. In this section, we outline the qualitative effects predicted depending on whether the adjectives in question take high or low scope. (In Section \ref{sec:modelling} below, we will show exactly how these predictions are derived and specify models that make quantitative predictions.)

%A positive answer to this question would predict no difference between Contexts 1 and 2, whereas a negative answer would predict a dispreference for the bag resolution in Context 1 compared to Context 2 driven by the presence of a bag that does not contain a rabbit in it, and whose size is greater than any of the rabbit-containing bags in the display.
%These predictions are derived from the different nature of the Comparison Classes available to our participants for the evaluation of the relative adjective {\em big}.  

We start with the predictions for the positive form adjective.
To the extent that high-scope readings are available for the positive form adjective, participants should consider comparison classes of rabbit-containing bags, excluding any rabbitless bags.
%consider Comparison Classes that are compatible with the available linguistic information up to and including the adjective. Based on this, the Comparison Class should consist of bags or boxes that crucially contain rabbits in them.
However, if the high-scope reading of the adjective is not available, participants should only consider comparison classes that consist of all the bags in the context, regardless of whether they have a rabbit in them or not.

In the context of our experiment, the latter situation (low-scope for the positive form) would translate into a lower target selection rate of the rabbit in the medium bag in Context 1 compared to Context 2. This is due to the fact that the biggest bag in the display---which does not contain a rabbit---is not factored into the evaluation of the adjective when it takes high scope.
If, on the other hand, a high-scope reading is not available, the comparison class  should consist of all the bags in the display, regardless of whether they contain a rabbit or not in them. 
Finally, in Context 3 we predict that the positive form should exhibit an effect of the competing object in the display to the extent that it is interpreted with low scope. If the positive adjective is interpreted with high scope, then the bag resolution should be statistically on par with the box resolution, because the competing bag would be ignored.
%Regarding the comparative conditions, neither of the two views under evaluation predict differences between Contexts 1 and 2, since comparative adjectives are not interpreted with respect to a Comparison Class, and should therefore not display any context-sensitive effects (See $\S$ \ref{cmp-semantics} for further details).%The predictions for the cmp need to be better spelled out.

Regarding the comparative, we would expect comparable target selection rates for the bag resolution in Contexts 1 and 2 to the extent that a high-scope reading is preferred over a low-scope reading. 
In Context 3, participants should be closer to chance, the more likely a high-scope reading is.

If high-scope readings are not available for the comparative, the bag resolution should be undefined in Contexts 1 and 3, due to the fact that the cardinality-of-two presupposition associated with comparatives would not be satisfied (as there would be three bags in the display). 
Furthermore, participants should be at chance in Context 2, since both resolutions satisfy the low scope reading of the comparative.

\begin{figure}[h]
    \includegraphics[width=4in]{images/predictions.png} 
\end{figure}



\subsection{Results}

Experimental results are shown in Figure \ref{results}, which plots the probability of bag resolution (\emph{i.e.} proportion of clicks to the rabbit in the medium bag \emph{vs.} clicks on the the rabbit in the medium box)\footnote{this is not completely accurate. this plot still contains the few clicks the non-target objects. If we want to plot clicks to medium bag vs. everything else, the chance line needs to be changed accordingly.} in each of the three contexts tested. 
%The yellow line corresponds to chance after correcting for responses that did not correspond to any of these two objects (a total of X). 

To analyze Contexts 1 and 2, we constructed a Bayesian hierarchical mixed logistic regression model using the \verb!brm()! function of the \verb!R! package \verb!brms! (B\"urkner, 2017).
The model predicts clicks to the target referent corresponding to the bag resolution (\emph{i.e.}, the rabbit in the medium bag) using {\sc Adjective Type}, {\sc Display Type} and their interaction as main effect predictors, as well as {\sc Subjects} and {\sc Items} as random effects (see Table \ref{stats-interaction} for the full model specification). 
The model was fit using 4 chains with 1000 warm-up samples and 1000 posterior samples, for a total of 4000 posterior samples, using uninformative priors and the Bernoulli family. 
The chains mixed well (\emph{e.g.} all R-hats were 1.01 or closer to 1) and there were no divergent transitions after warm-up.\footnote{Unless otherwise noted, the same settings were used for all the remaining analyses reported below.} 
For each of the models described below, we report the mean posterior estimates and 95\% credible condifence intervals, as well as tables containing the full model specification and main effects coefficients.

Our results reveal that participants were less likely to choose the bag resolution in Context 1 compared to Context 2, as shown by the marginally significant interaction of {\sc Adjective Type} x {\sc Context Type} ($\beta$ = $-0.64[-1.32, 0.04]$, see Table \ref{stats-interaction}). 
To further explore this interaction, we compared the two adjective types in each of the two contexts separately. 
Results displayed a significant difference for the positive adjective ($\beta$ = $-0.47[-0.93,-0.01]$), see Table \ref{stats-posconds-comparison}), while the same comparison did not reach significance for the comparative form adjective ($\beta$ = $-0.37[-0.58,1.65]$, see Table \ref{stats-cmpconds-comparison}). 
To analyze Context 3, we constructed a model using {\sc Adjective Type} as main predictor. This comparison showed a marginally significant effect of {\sc Adjective Type} ($\beta$ = $0.24[-0.07,0.56]$, Table \ref{context3-pos-cmp-comparison}), such that participants chose the bag resolution at a marginally significant higher rate in the comparative when compared to the positive form adjective. 
However, our critical prediction for Context 3 was that participants should be at chance for the bag \emph{vs.} box resolution when the instruction contained a comparative, whereas they should be below chance for the condition containing a positive form adjective.
To address this prediction, we submitted data from each adjective type separately to a model containing only the intercept (see Tables \ref{context3-pos-intercept-comparison}-\ref{context3-cmp-intercept-comparison}).
As predicted, model outputs revealed that the behavior displayed by participants was significantly different than chance for the positive form adjective ($\beta$ = $-0.44[-0.69,-0.21]$, see Table \ref{context3-pos-intercept-comparison}) but not for the comparative ($\beta$ = $-0.18[-0.44, 0.06]$, see Table \ref{context3-cmp-intercept-comparison}).

\begin{figure}
\centering
<<results1, echo=FALSE, cache=TRUE, warning=FALSE, message=FALSE, fig.width = 4, fig.height=4.5>>=

#library(png)
#library(grid)

data<-read.csv("exp2-m1-p1-p2-p3b-cleaned.csv", header=TRUE) #225 participants

data$displaytype1[data$displaytype=="abs-rel"]= "Context 1"
data$displaytype1[data$displaytype=="abs-both"]= "Context 2"
data$displaytype1[data$displaytype=="both-rel"]= "Context 3"

data$adjtype2[data$adjtype=="pos"]= "big"
data$adjtype2[data$adjtype=="cmp"]= "bigger"

#data$barplot <-"bag3/distractor"
#data$barplot[data$selection=="target2"]= "bag2"
#data$barplot[data$selection=="target1"]= "box2"
#data$barplot[data$selection=="small-box"]= "box1"
#data$barplot[data$selection=="small-bag"]= "bag1"


data$stim.version<-paste(data$stimnum,data$version,sep="-")

data$stim.version<-as.factor(data$stim.version)
#data$displaytype1<-as.factor(data$displaytype1)
#data$adjtype2<-as.factor(data$adjtype2)
#data$stimnum<-as.factor(data$stimnum)
data$target<-as.numeric(as.character(data$target))

#data$cont.adj<-paste(data$displaytype1,data$adjtype2,sep="-")

#myColors <- c("#CC79A7","#2392E9","lightblue","#F0E442","#C44D00")

#"#2392E9" -> box2
#"lightblue" -> box1
#"#F0E442" -> bag1
#"#C44D00-> bag2
#"#CC79A7" -> bag3/distractor

#devtools::install_version('textfeatures', version='0.2.0', repos='http://cran.us.r-project.org')

#df.data.item <- data %>%
#  group_by(displaytype1, adjtype2, stimnum) %>%
#  tidyboot_mean(column = target)


####### For future iterations of the experiment, and if we want to preregister, change this item #####
#data1<-subset(data, stimnum!=5)
#data2<-subset(data, stimnum!=12)  
#data3<-subset(data2, stimnum!=5)  

#df.data.general1 <- data1 %>%
#  group_by(displaytype1, adjtype2) %>%
 # tidyboot_mean(column = target)
#######

#summary <- summarySE(data, 
#                                   measurevar="target", 
#                                   groupvars=c("displaytype1",
#                                               "adjtype2"
#                                              ),
#                                                na.rm = TRUE)
#p<-ggplot(data=summary, aes(x=displaytype1, y=target,fill = adjtype2)) +
#    geom_col(position = position_dodge(0.8),
#           aes(y = target),
#           width = 0.8,
 #          alpha = 0.4,
#           color = 'black')+
#    geom_linerange(aes(ymin = target-ci, ymax = target+ci),
#              position = position_dodge(0.8), size = 1.2,
 #             color = 'black')
#p

df.data.item <- data %>%
  group_by(displaytype1, adjtype2, stimnum) %>%
  tidyboot_mean(column = target)

df.data.general <- data %>%
  group_by(displaytype1, adjtype2) %>%
  tidyboot_mean(column = target)

#code below partially due to MH Tessler

plot.general<-df.data.general %>%
  ggplot(., aes( x = displaytype1, y = mean, fill = adjtype2))+
  #theme_black()+
  geom_hline(yintercept = 0.5, lty = 2, alpha = 0.5, color = 'black')+
  geom_col(position = position_dodge(0.8),
           aes(y = mean),
           width = 0.8,
           alpha = 0.4,
           color = 'black')+
  geom_point(data = df.data.item,
             position = position_jitterdodge(),
             inherit.aes = F, aes(x = displaytype1, y = mean, color = adjtype2),
             alpha = 0.25)+
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper),
              position = position_dodge(0.8), size = 1.2,
              color = 'black')+ 
  ylab("Probability of bag resolution")+
  #facet_wrap(~ me) +
  scale_y_continuous(limits = c(0, 1), breaks = c(0, 0.5, 1)) +
  scale_fill_manual(values = c("#009E73", "#CC79A7"))+
  scale_color_manual(values = c("#009E73", "#CC79A7"))+
  xlab("")+
  theme(text = element_text(size=18),
      ) +
  theme(legend.title=element_blank())+
  theme(axis.text.x = element_text(angle = 0, vjust = 0.55, hjust = 0.5),
        legend.position = "bottom",
        legend.spacing.x = unit(.2, 'cm'))
plot.general



# data$barplot <- factor(data$barplot,levels=c("bag3/distractor","box2","box1","bag1","bag2"))
# 
# names(myColors) <- levels(data$barplot)
# fillScale <- scale_fill_manual(name = "barplot",values = myColors)
# 
# data$new.order <- data$barplot
# data$new.order <-factor(data$new.order,levels=c("bag2","box2","bag1","box1","bag3/distractor"))
# 
# stacked.barplot <- data %>% 
#   group_by(displaytype1, new.order,adjtype2) %>% 
#          tally()
# 
# counts <- aggregate(stacked.barplot$n ,by=list(stacked.barplot$displaytype1 ,stacked.barplot$adjtype2),sum)
# 
# 
# pics = data.frame(images=list.files("~/Documents/haddock_descriptions/images/contexts-plots", full.names = T), stringsAsFactors = F)
# 
# pics$names = gsub("[a-zA-Z]|[[:punct:]]","", pics$images)
# 
# stacked.barplot$names <- gsub("[a-zA-Z]|[[:space:]]","", stacked.barplot$displaytype1)
# 
# stacked.barplot.img<- merge(stacked.barplot, pics, by="names")
# 
# #img = readPNG(contexts.col$images[1])
# #g =  rasterGrob(img, interpolate=TRUE)
# 
# contexts.col<-stacked.barplot.img %>%
#             filter(new.order=="bag2" & adjtype2=="big")
# 
# PLOT<-ggplot(stacked.barplot.img, aes(fill=new.order, group=displaytype1, y=n, x=displaytype1)) + 
#   geom_bar(position="fill", stat = "identity") + 
#   fillScale + 
#   theme_bw() +
#   ylab("Proportion of Referent Selection")+
#   theme(axis.text.x = element_text(angle = 0, vjust = 0.55, hjust = 0.5),
#         legend.position = "bottom",
#         legend.spacing.x = unit(.2, 'cm')) +
#   theme(
#    strip.background = element_rect(
#      color="black", fill="white", size=0.5, linetype="solid"
#      )) +
#   theme(text = element_text(size=15),
#       ) +
#   theme(legend.title=element_blank())+
#   xlab("Display Type")+
#   facet_wrap(~adjtype2) 
# 
# 
# 
# g = list()
# for(i in 1:nrow(contexts.col)){
#   img = readPNG(contexts.col$images[i])
#   g[[i]] =  rasterGrob(img, interpolate=TRUE)
#   PLOT = PLOT +
#     annotation_custom(grob=g[[i]], xmin=i-0.4, xmax=i+0.4, ymin=-0.2, ymax=0.5)
# 
# }
# 
# PLOT


#g = list()
#for(i in 1:nrow(contexts.col)){
#  img = readPNG(contexts.col$images[i])
#  g[[i]] =  rasterGrob(img, interpolate=TRUE)
#  plot.general = plot.general +
#    annotation_custom(grob=g[[i]], xmin=i-0.23, #xmax=i+0.23, ymin=-0.5, ymax=0.1)

#}

#plot.general
   

@
\caption{Results for Experiment 1. Proportion of responses corresponding to the bag resolution vs. box resolution in each of the six conditions tested. The error bars represent Bootstrapped 95\% confidence intervals.}
\label{results}
\end{figure}

<<Stats, echo=FALSE, cache=TRUE, warning=FALSE, message=FALSE, fig.width = 13, fig.height=3>>=

#merge stim and version colum
data$stim.version<-paste(data$stim, "", data$version)

#remove both-rel condition (context 3) to check relevant interaction

data.interaction = subset(data, displaytype!="both-rel")

#Column we are trying to predict data$target1

#Different labels we've used for the different kinds of displays
#"abs-rel" same/diff+competitor, aka context 1
#"abs-both" same/diff-competitor, aka context 2
#"both-rel" same/same+competitor, aka context 3


### Bayesian analysis ###
#for model comparison loo()
#data.interaction2 comares contexts 1 and 2
#https://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup


model1<- brm(
  formula = target ~ adjtype*displaytype +
    (1+adjtype*displaytype | usernum_unique)+(1+adjtype*displaytype | stim),
    data = data.interaction,
    family = "bernoulli",
    control=list(adapt_delta=0.99),
    iter = 2000,
    chains = 4,
    cores = 4
)



#Run model to check that Condition 3 is different from intercept

@


\begin{verbbox}target ~ AdjType*DispType + (1 + AdjType*DispType | Sub)+
              (1 + AdjType*DispType | item)\end{verbbox}
\begin{table}
\center
<<Model1-table, echo=FALSE, cache=FALSE, warning=FALSE, message=FALSE, fig.width = 13, fig.height=3>>=

model1.output<-model1 %>%
  fixef(.) %>% 
  kable()
model1.output

@
\theverbbox 
\caption{Summary of the mixed-effects logistic regression model predicting clicks to the referent corresponding to the the bag resolution in Contexts 1 and 2 for the postive and comparative form adjectives of Experiment 1 (N = 225).}
\label{stats-interaction}
\end{table}

<<Model2, echo=FALSE, cache=TRUE, warning=FALSE, message=FALSE, fig.width = 13, fig.height=3>>=

data.pos = subset(data.interaction, adjtype=="pos")

model2<- brm(
  formula = target ~ displaytype +
    (1+displaytype | usernum_unique)+(1+displaytype | stim),
    data = data.pos,
    family = "bernoulli",
    control=list(adapt_delta=0.99),
    iter = 2000,
    chains = 4,
    cores = 4,
)

@

\begin{verbbox}target ~ DispType + (1 + DispType | Sub)+
              (1 + DispType | item)\end{verbbox}
\begin{table}
\center
<<Model2-table, echo=FALSE, cache=FALSE, warning=FALSE, message=FALSE, fig.width = 13, fig.height=3>>=
  
model2.output<- model2 %>% 
  fixef(.) %>% 
  kable()
model2.output

@
\theverbbox 
\caption{Summary of the mixed-effects logistic regression model predicting clicks to the referent corresponding to the the bag resolution in Contexts 1 and 2 for the postive form adjective (Experiment 1).}
\label{stats-posconds-comparison}
\end{table}

<<Model3, echo=FALSE, cache=TRUE, warning=FALSE, message=FALSE, fig.width = 13, fig.height=3>>=

data.cmp = subset(data.interaction, adjtype=="cmp")

model3<- brm(
  formula = target ~ displaytype +
    (1+displaytype | usernum_unique)+(1+displaytype | stim),
    data = data.cmp,
    family = "bernoulli",
    control=list(adapt_delta=0.99),
    iter = 2000,
    chains = 4,
    cores = 4,
)
@

\begin{verbbox}target ~ DispType + (1 + DispType | Sub)+
              (1 + DispType | item)\end{verbbox}
\begin{table}
\center
<<Model3-table, echo=FALSE, cache=FALSE, warning=FALSE, message=FALSE, fig.width = 13, fig.height=3>>=


model3.output<- model3 %>% 
  fixef(.) %>% 
  kable()
model3.output

@
\theverbbox
\caption{Summary of the mixed-effects logistic regression model predicting clicks to the referent corresponding to the the bag resolution in Contexts 1 and 2 for the comparative form adjective (Experiment 1).}
\label{stats-cmpconds-comparison}
\end{table}

<<Model4-6, echo=FALSE, cache=TRUE, warning=FALSE, message=FALSE, fig.width = 13, fig.height=3>>=

data.context3<-subset(data, displaytype1=="Context 3")
data.pos.context3<-subset(data, displaytype1=="Context 3" & adjtype2=="big")
data.cmp.context3<-subset(data, displaytype1=="Context 3" & adjtype2=="bigger" )

#comparison pos cmp in condition 3
m4<- brm(
  formula = target ~ adjtype2 +
    (1 + adjtype2| usernum_unique)+(1 + adjtype2| stim),
    data = data.context3,
    family = "bernoulli",
    control=list(adapt_delta=0.99),
    iter = 2000,
    chains = 4,
    cores = 4,
)

#comparison pos to the intercept
m5<- brm(
  formula = target ~ 1 +
    (1  | usernum_unique)+(1 | stim),
    data = data.pos.context3,
    family = "bernoulli",
    control=list(adapt_delta=0.99),
    iter = 2000,
    chains = 4,
    cores = 4,
)

data.cmp.context3<-subset(data, displaytype1=="Context 3" & adjtype2=="bigger")

#comparison cmp to the intercept
m6<- brm(
  formula = target ~ 1 +
    (1 | usernum_unique)+(1 | stim),
    data = data.cmp.context3,
    family = "bernoulli",
    control=list(adapt_delta=0.99),
    iter = 2000,
    chains = 4,
    cores = 4,
)



@

\begin{verbbox}target ~ AdjType + (1 + AdjType | Sub)+
              (1 + AdjType | item)\end{verbbox}
\begin{table}
\center
<<Model4-table, echo=FALSE, cache=FALSE, warning=FALSE, message=FALSE, fig.width = 13, fig.height=3>>=


model4.output<- m4 %>% 
  fixef(.) %>% 
  kable()
model4.output

@
\theverbbox 
\caption{Summary of the mixed-effects logistic regression model predicting clicks to the referent corresponding to the the bag resolution in Context 3 for the postive and comparative form adjectives (Experiment 1).}
\label{context3-pos-cmp-comparison}
\end{table}



\begin{verbbox}target ~ 1 + (1 | subj)+(1 | stim)\end{verbbox}
\begin{table}
\center
<<Model5-table, echo=FALSE, cache=FALSE, warning=FALSE, message=FALSE, fig.width = 13, fig.height=3>>=


model5.output<- m5 %>% 
  fixef(.) %>% 
  kable()
model5.output

@
\theverbbox 
\caption{Context 3 pos comparison to intercept}
\label{Summary of the mixed-effects logistic regression model predicting clicks to the referent corresponding to the the bag resolution in Contexts 3. Comparison of the positive form adjective to the intercept (Experiment 1).}
\end{table}

\begin{verbbox}target ~ 1 + (1 | subj)+(1 | stim)\end{verbbox}
\begin{table}
\center
<<Model6-table, echo=FALSE, cache=FALSE, warning=FALSE, message=FALSE, fig.width = 13, fig.height=3>>=


model6.output<- m6 %>% 
  fixef(.) %>% 
  kable()
model6.output

@
\theverbbox 
\caption{Summary of the mixed-effects logistic regression model predicting clicks to the referent corresponding to the the bag resolution in Contexts 3. Comparison of the comparative form adjective to the intercept (Experiment 1).}
\label{context3-cmp-intercept-comparison}
\end{table}

\textbf{TODO:} Make the labels in tables more transparent. Also, each time models are run, numbers change slightly. Find a way to automatically generate results in the body of the text.
Discuss with Roger what precise inferences we can make by comparing the two adjectives in Context 3 to chance. 

\subsection{Discussion}

Our results show that target selection is modulated by the presence in the visual display of contextual referents that are incompatible with previous linguistic material for positive form adjectives but not for comparative adjectives.
These findings suggest that relative readings are available for comparative form adjectives, but not for positive form adjectives, and that therefore only the former can scope out of its base-position.
%More importantly, our results indicate that the threshold variable posited as part of the meaning of relative adjectives is resolved by accessing global contexts, such that the NP receives the same interpretation regardless of whether it is syntactically nested or not. 
%Future research will need to determine whether this is also the case for stacked adjectives contained in non-nested descriptions (\emph{e.g.}, the pretty big house). 


%These results point to an interesting difference between ours and previous work on the interactions between meaning and context.
%Sedivy and others after her found that pragmatic reasoning reasoning of context that leads to 
%Point out that that other interactions between semantic meaning and context result in pragmatic strengthening, whereas in this case we have weakening.


Our results suggest that positive form adjectives tend to be interpreted with low scope, while comparative form adjectives are interpreted with high scope. However, they also suggest that the scope preferences of the two adjectives under consideration may not be categorical. In the following section, we develop precise computational models that allow for mixtures of high and low scope, in order to determine precisely what the underlying scope probabilities are.


\section{Modelling}

\subsection{Semantic Assumptions}
\label{semantic-assumptions}

\subsubsection{Positive (\ol{big})}

Let us begin by discussing our semantics for positive form gradable adjectives like \ol{big}. 
We assume that such expressions are evaluated relative to a given threshold $\theta$, which must be exceeded in order for the gradable adjective to hold of a given referent. 
%We assume furthermore that what counts as `big' differs depending on the type of object whose size is in question. 
%Within a context, we have different thresholds for different types of objects, or comparison classes. 
%$\theta(\ol{bag})$ is the threshold for bags, for example, in a given context.

Writing `the denotation of $\alpha$ relative to context $C$ and threshold $\theta$' as $\valueof{\alpha}^{\theta,C}$, we will say that $\valueof{\alpha}^{\theta,C}(r) = \true$ if referent $r$ falls under description $\alpha$, relative to $\theta$ and $C$.
What it takes for $b$ to count as a \ol{big bag}, relative to threshold $\theta$ and context $C$, is the following:
\begin{enumerate}
  \item $b$ is in $C$
  \item $b$ is a bag:\\
  $\valueof{\ol{bag}}^{\theta,C}(b) =\true$
  \item $b$'s size exceeds the threshold required for bags to count as \ol{big}:\\
  $\textsf{size}(b)>\theta$
\end{enumerate}
Thus if all of the above conditions are met, then $\valueof{\ol{big bag}}^{\theta,C}(b)=\true$.

\textcolor{red}{We have to define high scope for the positive! Under the hood it's all done with the threshold; the comparison class just constrains the prior over thresholds.}


\subsubsection{Definite article}

Now let us consider how to analyze {\em the big bag}.
We entertain two alternative analyses of the definite article {\em the}. 
On what we will refer to as the \textbf{standard analysis}, the definite article carries a presupposition of uniqueness relative to some given context.
Thus, \ol{the big bag} denotes the unique bag in some given context $C$ that counts as `big', as determined by whether or not it exceeds a given threshold $\theta$.  To serve as the referent for a definite description of the form \ol{the NP}, a given referent $r$ must satisfy the following conditions:
\begin{enumerate}
\item $r$ satisfies NP, relative to $\theta$ and $C$:\\
$\valueof{\textnormal{NP}}^{\theta,C}(r) = \true$ 
\item No distinct $r'\in C$ satisfies NP, relative to $\theta$ and $C$.
\end{enumerate}

By extension, \ol{the rabbit in the big bag} denotes the unique rabbit (in some given context $C$) that is in $b$, 
where $b$ is the unique bag in $C$ that is big, according to a given threshold $\theta$.
Thus, the non-trivial conditions that a given referent $r$ must satisfy in order to fall under the description \ol{the rabbit in the NP}, 
relative to context $C$ and threshold $\theta$, 
are the following:
\begin{enumerate}
    \item $r$ is a rabbit in $C$:\\
     $\valueof{\ol{rabbit}}^{\theta,C}(r) =\true$
    \item $r$ is in some $b$ such that:\\
    $\valueof{\ol{in}}^{\theta,C}(b)(r) =\true$, where:
    \begin{itemize}
        \item $b$ satisfies \ol{NP}, relative to $\theta$ and $C$:\\
        $\valueof{\ol{NP}}^{C,\theta}(b) = \true$ 
        \item No distinct $b'$  satisfies \ol{NP}, relative to $\theta$ and $C$
    \end{itemize}
    \item No distinct $r' \in C$ meets conditions 1-2.
\end{enumerate}
%
Thus uniqueness is enforced at both the inner and outer layers of the description, relative to a given context.

Another analysis of definite descriptions that we will entertain is what we will call \textbf{Bumford's}. \citet{bumford:2017} offers a semantic analysis of Haddock descriptions in which the existence and uniqueness components may enter the composition at different stages, with other material intervening. 
The existence component ensures that a discourse referent is associated with the nominal. 
The uniqueness component ensures that the discourse referent cannot be mapped to more than one entity, in light of the restrictions that have been put on it. The restrictions put on the discourse referent may not be limited to the descriptive material within the definite description; 
surrounding descriptive material may accumulate before uniqueness is checked. In particular, the uniqueness component of the inner definite in an expression of the form \ol{the rabbit in the big bag} may take scope above \ol{rabbit}. 
Interpreted with such high scope, the definite article serves merely to ensure that there is no more than one rabbit/big-bag pair such that the rabbit is in the big bag. 
As far as the definite article is concerned, there may well be another big bag, as long as it doesn't contain a rabbit. 
In other words, this definite article does not require uniqueness with respect to the property `big bag'. 

Under a high-scope construal of the uniqueness component of the definite article, \ol{rabbit in the big bag} is almost synonymous with \ol{rabbit in a big bag}, then, but not entirely. The difference in meaning would only be visible in a scenario in which a rabbit was in multiple bags -- something very hard to imagine. The distinction is easier to fathom using an example like \ol{the singer with the gold bracelet}. Even on a high scope construal, this description could only be true if a singer is wearing a single bracelet, whereas \ol{the singer with a gold bracelet} could truthfully hold of a singer that has multiple bracelets (although pragmatics would suggest that he or she was only wearing one). As this kind of situation (e.g.\ one rabbit - multiple bags) does not occur in our experimental stimuli, the difference between {\em a} and high-scope {\em the} effectively disappears in our setting. 

Thus, under the high-scope construal, the non-trivial conditions that a given referent $r$ must satisfy in order to fall under the description \ol{the rabbit in the NP}, 
relative to context $C$ and threshold $\theta$, 
are just the following:
\begin{enumerate}
    \item $r$ is a rabbit in $C$:\\
     $\valueof{\ol{rabbit}}^{\theta,C}(r) =\true$
    \item $r$ is in some $b$ such that:\\
    $\valueof{\ol{in}}^{\theta,C}(b)(r) =\true$, where:
    \begin{itemize}
      \item $\valueof{\ol{NP}}^{C,\theta}(b) = \true$
    \end{itemize}
    \item No distinct $r' \in C$ meets conditions 1-2.
\end{enumerate}
The last condition is the contribution of the outer definite article, which we assume is interpreted without any scope-taking placing additional constraints on the rabbit. 
When these conditions are met, $\valueof{\ol{the rabbit in the NP}}^{\theta,C}(r) =\true$, on Bumford's analysis. The main difference between Bumford's analysis and the standard analysis is what constraints are put on $b$, whether it just has to satisfy the descriptive content of the inner NP (as on Bumford's analysis), or whether it must furthermore be the only entity in $C$ that does so.

\subsubsection{Comparative}
\label{cmp-semantics}

We will consider two alternative analyses of the comparative \ol{bigger} corresponding to the he well-known distinction between {\em relative} and {\em absolute} readings of superlatives \citep{szabolcsi:1986,heim:1999}.
Although the distinction has mainly been discussed in regards to superlatives, it also applies to comparatives, as argued in the appendix.
Just as {\em the highest shelf} in {\em the book on the highest shelf} can refer to either the absolutely highest shelf (absolute reading) or the highest shelf {\em that a book is on} (relative reading), {\em the higher shelf} in {\em the book on the higher shelf} can refer to the higher of two shelves (absolute reading), or it can refer to the higher of the two shelves {\em that a book is on} (relative reading).

According to Bumford, superlatives can be interpreted either high, with the determiner, or low, where the positive form adjective is interpreted. A low scope position corresponds to an absolute interpretation. Note that in principle, the superlative can be interpreted low even if the determiner is interpreted high. On a low interpretation of the superlative combined with a high interpretation of the definite article, \ol{the rabbit in the biggest bag} is true of $r$ if and only if:
%
\begin{enumerate}
    \item $r$ is a rabbit in $C$:\\
     $\valueof{\ol{rabbit}}^{\theta,C}(b) =\true$
    \item $r$ is in some $b$ such that:\\
        $\valueof{\ol{in}}^{\theta,C}(r,b) =\true$ where
        \begin{itemize}
    \item $b$ is a bag in $C$:\\
     $\valueof{\ol{bag}}^{\theta,C}(b) =\true$
    \item $b$ is bigger than any other bag in $C$:\\
    For all $b'$ such that $\valueof{\ol{bag}}^{\theta,C}(b') =\true$:
    \textsf{size}($b$) $>$ \textsf{size}($b'$)
    \end{itemize}
\item No referent distinct from $r$ in $C$ meets conditions 1-2.
\end{enumerate}

On a high interpretation of the superlative, combined with a high interpretation of the definite article, \ol{the rabbit in the biggest bag} is true of $r$ if and only if it is a rabbit in a bag that is bigger than any other {\em rabbit-containing} bag:
%
\begin{enumerate}
    \item $r$ is a rabbit in $C$:\\
     $\valueof{\ol{rabbit}}^{\theta,C}(b) =\true$
    \item $r$ is in some $b$:\\
        $\valueof{\ol{in}}^{\theta,C}(r,b) =\true$ where:
        \begin{itemize}
          \item $b$ is a bag in $C$:\\
          $\valueof{\ol{bag}}^{\theta,C}(b) =\true$
          \item $b$ is bigger than any other rabbit-containing bag in $C$:\\
          For all $b'$ such that:
            \begin{itemize}
              \item $\valueof{\ol{bag}}^{\theta,C}(b') =\true$
              \item and there is some $r'$ such that:
                \begin{itemize}
                  \item $\valueof{\ol{rabbit}}^{\theta,C}(r')$
                  \item $\valueof{\ol{in}}^{\theta,C}(r',b')$
                \end{itemize}
            \end{itemize}
          \textsf{size}($b$) $>$ \textsf{size}($b'$)
        \end{itemize}
\item No referent distinct from $r$ in $C$ meets conditions 1-2.
\end{enumerate}

The same two possibilities are available in principle for comparatives. The only difference is that comparatives are only defined when the comparison class contains exactly two elements. \textcolor{red}{(Where/how to justify this?)}%
\footnote{%
It is possible to find attestations of {\em the bigger of the three}, but there are very few attestations of {\em the bigger of the $n$} for larger $n$s, and it appears that {\em the larger of the three} is licensed only in contexts where there are two sizes, one larger than the other, and the referent of {\em the larger of the three} bears the larger of the two sizes, while the other two bear the smaller of the two sizes. 
To account for such cases, we could modify our assumptions so that {\em larger N} means something like {\em larger of the Ns}, where the comparison class consists of two pluralities of Ns, each with their own aggregate size. 
Because we never had multiple Ns whose sizes could be treated as the same in our experiments, we ignore this wrinkle.%
}
The low interpretation of the comparative, then, combined with the high interpretation of the definite article is as follows, for the expression \ol{the rabbit in the bigger bag}:
%
\begin{enumerate}
    \item $r$ is a rabbit in $C$:\\
     $\valueof{\ol{rabbit}}^{\theta,C}(b) =\true$
    \item $r$ is in some $b$:\\
        $\valueof{\ol{in}}^{\theta,C}(r,b) =\true$, where:
        \begin{itemize}
          \item $b$ is a bag in $C$:\\
            $\valueof{\ol{bag}}^{\theta,C}(b) =\true$
          \item $b$ is bigger than the other bag in $C$:
          \begin{itemize}
            \item There is exactly one referent $b'\neq b$ such that $\valueof{\ol{bag}}^{\theta,C}(b') =\true$.
            \item \textsf{size}($b$) $>$ \textsf{size}($b'$)
          \end{itemize}
        \end{itemize}
\item No referent distinct from $r$ in $C$ meets conditions 1-2.
\end{enumerate}
The standard analysis of the definite article is also compatible with a low interpretation of the comparative, and this would merely add a uniqueness clause for the referent of the embedded description.

A high interpretation of the comparative necessitates a high interpretation of the definite article. On such an interpretation, \ol{the rabbit in the bigger bag} is true of $r$ if and only if:
%
\begin{enumerate}
  \item $r$ is a rabbit in $C$:\\
    $\valueof{\ol{rabbit}}^{\theta,C}(b) =\true$
  \item $r$ is in some $b$:\\
    $\valueof{\ol{in}}^{\theta,C}(r,b) =\true$ where:
    \begin{itemize}
      \item $b$ is a bag in $C$:\\
        $\valueof{\ol{bag}}^{\theta,C}(b) =\true$
      \item $b$ is bigger than the other rabbit-containing bag in $C$:
        \begin{itemize}
          \item There is exactly one referent $b'\neq b$ such that:
            \begin{itemize}
              \item $\valueof{\ol{bag}}^{\theta,C}(b') =\true$
              \item there is some $r'$ such that:
                \begin{itemize}
                  \item $\valueof{\ol{rabbit}}^{\theta,C}(r')$
                  \item $\valueof{\ol{in}}^{\theta,C}(r',b')$
                \end{itemize}
            \end{itemize}
            \item \textsf{size}($b$) $>$ \textsf{size}($b'$)
        \end{itemize}
      \end{itemize}
    \item No referent distinct from $r$ in $C$ meets conditions 1-2.
\end{enumerate}
On the high interpretation of the comparative, then, the comparison class consists of the set of rabbit-containing bags, rather than the full set of bags. No bag that does not contain a rabbit will have any impact on whether the description truthfully and felicitously applies to the referent.



\subsection{Computational Models}
\label{computational-model}

We implement a series of RSA models where the pragmatic listener infers a referent for an incomplete description. This process also involves reasoning under uncertainty about the threshold for the positive form adjective. In this section, we restrict our attention to models with a Bumfordian treatment of the definite article, but we consider alternatives in Section \ref{sec:cco}.

%We also allow models to consider subsets of the visual context, and reason under uncertainty about what context the speaker has in mind.

\subsubsection{Literal Listener}

The literal listener infers a referent $r$ given a description $d$, a context $C$ and a threshold $\theta$ proportionally to 1) whether the description is true of $r$ in $C$ given the threshold value; and 2) the prior probability of $r$.
%The threshold $\theta$ is used in the interpretation of the relative adjective {\em big} and its comparative form {\em bigger} (see semantics in the previous section). 
In other words, the literal listener discards referents that do not satisfy the semantic requirements of the description, and assigns a posterior probability to any remaining referent as a function of the referent's prior probability (\ref{literal-listener}).

\begin{equation}
  L_0(r\given d,C,\theta) \propto \llbracket d \rrbracket^{C,\theta}(r)\cdot P(r) 
  \label{literal-listener}
\end{equation}


In this model, both $\theta$ and $C$ are treated as lifted variables, which means that their value is not resolved at the level of the model where they are first called (i.e., at the literal listener level).
Rather, these variables are `lifted' all the way up to the pragmatic listener, where its value is resolved.

The posterior distribution in (\ref{literal-listener}) is undefinable if the existence and/or uniqueness presuppositions associated with the outer definite determiner are not satisfied, i.e., if $C$ does not contain exactly one referent $r$ that satisfies the description $d$ for the adjectival threshold $\theta$.
Presupposition failure is technically implemented by positing a special \textsf{fail} referent, with prior probability $\epsilon$. 
Otherwise, we assume an uninformative prior over referents, as shown in (\ref{undefined}).


\begin{equation} 
  P(r) =
    \begin{cases}
      \epsilon & \text{if } r = \textsf{fail}\\
      \text{uniform} & \text{otherwise} 
      \label{undefined}
    \end{cases}
\end{equation}


\paragraph{Implementation of Reference Failure}

Reference failure is implemented by adding a sixth referent (rU) that is assigned by the literal listener when none of the five referents in the visual context satisfies the semantic requirements of the description, i.e., in cases where there is reference failure. 
For this to be possible, the meaning function is stated such that all descriptions are true of rU (see $\S$\ref{semantic-assumptions}). 
In order for rU to be dispreferred when any of the five referents in the display support the utterance, rU receives a signifantly smaller amount of probability in the prior, compared to any of the five referents in the maximal context (see quation (\ref{undefined})). 
In the model predictions reported below, the failure referent rU receives a prior probability of $\sim 0.04$, with the remaining referents receiving slightly less than $20\%$ respectively. 
This entails that the literal listener always assigns some amount of posterior probability to rU, as can be appreciated in Figures \ref{litlist-standard} and \ref{litlist-bumford}.
The figures also show that despite its low prior probability, the literal listener assigns probability of 1 to rU when no other referent is compatible with the utterance and there is therefore reference failure (e.g., when the utterance is {\em the rabbit in the bag}. This is due to the fact that there are always to possible referents compatible with this utterance in all the contexts tested).
Furthermore, this assymetry in the prior probabilities of the referents also ensures that, to the extent that some other referent is compatible with the utterance, rU will always receive less posterior probability than any other referent.



\paragraph{Implementation of Scopal Ambiguities}

As discussed above, the same string can be assigned two different underlying structures (Logical Forms, as it were). 
For both the positive and the comparative, Bumford's theory allows either a high or low scope construal.
The choice of construal is determined by free parameters in the model (posHighScopeConstrualProb and cmpHighScopeConstrualProb), ranging from 0 to 1, specifying the mixture.

%The higher the value of this parameter, the more likely the `bag' construal.
%In the simulations reported here, this parameter is set to .5 such that none of the two scopal configurtions is favored over the other.
%When the standard meaning for the definite determiner is adopted, the model makes no reference to this parameter, since the core assumption of the standard meaning theory is that the definite does not take scope and is always interpreted {\em in situ}.
%This means that under this semantics, there's only one possible reading for the determiner, namely the low scope construal. 
This can be observed in Figures \ref{litlist-standard} and \ref{litlist-bumford}, where the description {\em the rabbit in the bigger bag} given threshold 1 and the maximal context 1 is undefined for the rabbit in the medium bag when the standard meaning is considered (upper leftmost pannel of Figure \ref{litlist-standard}), but it's defined for that very same referent when Bumford's meaning is considered (upper leftmost pannel of Figure \ref{litlist-bumford}). 
This is due to the fact that the cardinality of two requirement of the comparative and the uniqueness requirement of the determiner are checked against only bags for the standard meaning, whereas depending on the scope, these two meaning requirements are checked against bags and/or bag-containing rabbits in Bumford's meaning.

\begin{figure}
\includegraphics[width=\linewidth]{litlist-standard.pdf}
\caption{Literal listener model predictions for standard meaning and no-cc}
\label{litlist-standard}
\end{figure}

\begin{figure}
\includegraphics[width=\linewidth]{litlist-bumford.pdf}
\caption{Literal listener model predictions for Bumford's meaning and no-cc}
\label{litlist-bumford}
\end{figure}


\textbf{TODO:} The heatmaps for lit-listener model are missing 'rabbit none box' utterance. Not sure why that is... This plot probably needs to be regenerated.
\textcolor{red}{The heat maps should be regenerated with either 0 or 1 probability for both pos and cmp high scope, rather than 0.5. Also can the labels be improved? I find them a bit confusing. --EEC}


\subsubsection{Speaker}

The speaker is modeled as a {\em softMax} agent that chooses a description $d$, given that she wants to convey the referent $r$ in context $C$ for the adjectival threshold $\theta$.
In choosing utterances, the speaker balances out two constraints: maximizing the likelihood that the literal listener will correctly identify the intended referent through the use of informative descriptions, while minimizing production cost. 
Informativity is modeled as negative surprisal (or positive log probability) of the referent in the posterior, whereas utterance cost $C(u)$, is directly proportional to the utterance length. Currently, the costs are set as follows: comparative 1.5; positive 1; 0.5 if the utterance does not contain an adjective; and 0 for the silence utterance. 
Finally, we assume a rationality parameter $\alpha$ of 1. 


\begin{equation} 
  S_1(d\given r,C,\theta) \propto \text{exp}(\alpha \times \text{ln}(L_0(r\given d,C,\theta)) -    \textsf{cost}(d)) 
  \label{speaker}
\end{equation} 


\begin{figure}
\includegraphics[width=\linewidth]{speaker-standard.pdf}
\caption{Speaker model outputs for standard meaning and no-cc}
\label{speaker-standard}
\end{figure}

\begin{figure}
\includegraphics[width=\linewidth]{speaker-bumford.pdf}
\caption{Speaker model outputs for Bumford's meaning and no-cc}
\label{speaker-bumford}
\end{figure}

Figures \ref{speaker-standard} and \ref{speaker-bumford} contain model outputs for the speaker for each of the two meanings considered.
Looking at the plots, one can see that the fact that the referent consisting of a rabbit in a medium bag ('rabbit bag 2') could not be described by any of the utterances in Contexts 1 and 3 when the standard meaning was considered percolates to the speaker level, where the silence utterance is the only option the speaker can choose if she wants to convey this referent under the standard meaning (see Figure \ref{speaker-standard}).

%Rabbit in the box is only possible for Bumford, again because standard is never defined in this circumstance.

\noindent
\textbf{TODO:} \\
\noindent
Discussion about assumed costs?

%\noindent
%speaker model outputs cost coefficient is set to 1, because higher values create a lazy speaker that always prefers silence (wrong result). The lit.listener model outputs was set to 3, but it should not matter because no cost is involved at that level. Things need to be rerun for dinal model outputs though

\subsubsection{Pragmatic Listener}

The pragmatic listener is modeled as a Bayesian agent that assigns posterior probabilities to referents $r$ given a masked description $d$, proportionally to the probability of the speaker using (any possible resolution of) $d$ to describe $r$ given context $C$ and assuming threshold $\theta$ (i.e., the likelihood), times the prior over referents given the context, the prior over thresholds given the context and a full description, and the prior over contexts (see equation \ref{pragmatic-listener}).


\begin{equation}
  \begin{array}{l}
    L_1(r\given d=N_1\textnormal{ in the (Adj) }\textsf{[masked]}) \propto \\
    \sum_C \sum_\theta \sum_{N_2} S_1(d=N_1\textnormal{ in the (Adj) }N_2\given r,C,\theta)\cdot P(r\given C)\cdot P                (\theta\given C,d)\cdot P(C)
  \end{array}
  \label{pragmatic-listener}
\end{equation}

For models without context coordination, the context $C$ always consists of the five referents present in the display ($C = \{r_1,r_2,r_3,r_4,r_5\}$).
In models that allow for Context Coordination, a context is any $C'$ such that $C'$ is in the powerset of $C$ ($C' \subseteq \mathcal{P}(C)$).

As seen in equation \ref{pragmatic-listener}, different types of priors modulate the probability of a given referent in the posterior; 
the prior probability of a referent $r$ given a context $C$ is uniform among the referents in the context and undefined otherwise. 
In the latter case, the referent receives a small but non-negligible probability $\epsilon$. 
Crucially, this value is fixed in models that do not use context coordination, but will vary in models that assume context coordination as a function of the context-referent pair under consideration. 

\begin{equation}
  P(r\given C) =
    \begin{cases}
      \epsilon & \text{if } r = \textsf{fail}\\
      \text{uniform among any } r \in C & \text{otherwise}
      \label{prior-referent-given-context}
    \end{cases}
\end{equation}


The prior over thresholds is also assumed to be uniform among the possible threshold values licensed by the context and the description. 
Possible threshold values are obtained by extracting the referents in the context that are in the extension of the nested noun (e.g., bag), which is taken to provide the Comparison Class against which the adjective is evaluated ([reference]).
This prior derives the dispreference for the bag resolution in conditions that contain more than two bags (i.e., Contexts 1 and 3), even if the biggest bag in the display does not contain an animal that matches the first noun in the description.
In such contexts, the prior probability of each of the thresholds licensed by the description and the context will be lower than the condition that only contains two bags (Context 2), since the prior probability is split among three possible thresholds, as opposed to two, as exemplified in Figure \ref{thres-fig}. Each threshold receives higher probability in the prior in context 2 compared to contexts 1 and 3.
This difference in the prior over threshold values results in higher posterior probabilities for the bag resolution compared to the box resolution, since the number of boxes in any given context is never greater than two.

\begin{figure}
\centering
  \begin{minipage}[c]{0.45\textwidth}
    \includegraphics[width=3.0in]{images/1thres.pdf}
    %\caption{Possible thresholds for the positive form adjective {\em big} in a context     including two bags.}
    \label{2bag-context}
  \end{minipage}
  \begin{minipage}[c]{0.45\textwidth}
    \includegraphics[width=3.0in]{images/2thres.pdf}
    %\caption{Possible thresholds for the positive form adjective {\em big} in a context     including three bags.}
    \label{3bag-context}
  \end{minipage}
  \label{thres-fig}
  \caption{Possible thresholds for the positive form adjective {\em big} in contexts     including two (left panel) and three (right panel) bags.}
\end{figure}

Finally, the last term in equation \ref{pragmatic-listener} corresponds to the prior over contexts.
In models that do not invoke Context Coordination, there is only one context considered by the listener, and so the prior probability of this context is 1.
For models that do involve Context Coordination, the prior probability over contexts (i.e., any element in the powerset of the set containing all referents) is determined by 
%the distribution resulting from the exponential function in \ref{context-prior}. 
a parameter $\gamma$.
For each referent, a coin weighted $\gamma$ is flipped in order to determine whether or not the referent is included in the context.
The higher $\gamma$ is, the greater the preference for larger contexts.
The resulting probability distribution is renormalized to exclude the empty context;
this ensures that the probability distribution over referents is well-defined.
%I got the error "All paths explored by Enumerate have probability zero" when I did not do this, but I don't know why --Liz

%This distribution is supported for the values corresponding to the cardinalities of the possible contexts. 
%When the parameter $\gamma = 1$, the resulting prior over contexts is the uninformative prior. 
%When the parameter is set $\gamma > 1$, the result is a skewed prior that places higher prior probability on contexts of bigger cardinalities.

%Finally, the last term in equation \ref{pragmatic-listener} samples contexts from a $beta$ prior with parameters $\alpha=2$ and $\beta =1$ that assigns higher probability to bigger contexts as shown in XX. [\textbf{This needs to be completed}]

% \begin{equation}
% \begin{multlined}
%   f(C) =  \frac{1}{Z}2^{\gamma \mid C\mid}\text{, where }Z =\sum_{C \in \mathcal{P}(C)}2^{\gamma\mid C\mid}\text{    , such that} \\
%   P(C) =
%   \begin{cases}
%     \text{Uniform for } \gamma = 0\\
%     \text{For } \gamma > 0\text{: Bigger contexts receive higher probability in the prior.}
%   \end{cases}
% \end{multlined}
%   \label{context-prior}
% \end{equation}

\textbf{The model results currently (November 25th) are derived using the assumption that the threshold categorically cannot be below the smallest. We are doing this because it seems to be the only way to get a preference for the bag overall; otherwise too much probability mass gets eaten up by non-targets (the smaller bag in particular, which has a rabbit in it). Update: As of January 6th, the same is still true.}


\section{Conclusion}

We have argued based on both distributional and experimental evidence that the comparison classes for gradable adjectives operate independently of the comparison classes for definite articles in the same noun phrase. Or, to put it in terms of scope: Gradable adjectives take low scope, even when the definite article takes high scope. These comparison classes do not march in lock step.

%From the perspective of Bumford's analysis this is not surprising.
%It might be surprising on a view where the CC for def and adj comes from context restriction?


Furthermore, we have argued that comparatives not only have the kinds of relative readings that superlatives have, but actually prefer them.



\bibliography{master}
\bibliographystyle{sp}


\appendix

\section{Simulations}

%In what follows, we present simulation results for the model described in $\S$\ref{computational-model}. 

\subsection{Best results}

\setlength\parindent{0em}
<<Plot-bestresults, echo=FALSE, cache=FALSE, warning=FALSE, message=FALSE, fig.width = 4.5, fig.height=2.7>>=

#color blind palette
#cbPalette <- c("#009E73", "#CC79A7","#E69F00", "#56B4E9",  "#F0E442", "#0072B2", "#D55E00",  "#999999")

# "#009E73" is a nice green
# "#CC79A7" is dark pink
# "#E69F00" is gold
# "#56B4E9" is sky blue
# "#F0E442" is yellow
# "#0072B2" is a darker blue
# "#D55E00" is a burnt orange
# "#999999" is grey

#pink and blue
#myColors <- c("#56B4E9","lightblue","pink","#CC79A7")

#pink and teal
#myColors <- c("#009AA3","#00CFC6","pink","#CC79A7")

#orange/yellow and blue
myColors <- c("#2392E9","lightblue","#F0E442","#C44D00","#CC79A7")

results$Container <- factor(results$Container,levels=c("box2","box1","bag1","bag2"))

#Create a custom fill scale 
#so that colors will be consistent even if not all levels are always present
names(myColors) <- levels(results$Container)
fillScale <- scale_fill_manual(name = "Container",values = myColors)

plot_result <- function (pragListenerLevel,
                         defArtMeaning,
                         adj,
                         cmpHighScopeConstrualProbValue,
                         posHighScopeConstrualProbValue,
                         allowUninformativeThresholdsValue) {
  gg_df <- subset(results, Adjective==adj & 
                    DefArtMeaning==defArtMeaning & 
                    Model=="haddock_model.wppl"  & 
                    ListenerLevel==pragListenerLevel & 
                    posHighScopeConstrualProb==posHighScopeConstrualProbValue & 
                    cmpHighScopeConstrualProb==cmpHighScopeConstrualProbValue &
                    allowUninformativeThresholds==allowUninformativeThresholdsValue)
  
  ggplot(gg_df, aes(x=Condition, y=Probability, fill=Container)) + 
    geom_bar(position="fill", stat="identity") +
    fillScale +
    theme_bw() +
    theme(axis.text.x = element_text(size=8),
          axis.text.y = element_text(size=10),  
          axis.title.x = element_text(size=10),
          axis.title.y = element_text(size=10),
          legend.title=element_text(size=10), 
          legend.text=element_text(size=10)
    ) +
    ylim(0,1) +
    xlab("Display Type") +
    ylab("Probability of Referent Choice") +
    ggtitle(paste("Model predictions for", adj),paste(defArtMeaning,paste0("L",pragListenerLevel),paste0("posHiScope:", posHighScopeConstrualProbValue),paste0("cmpHiScope:", cmpHighScopeConstrualProbValue),allowUninformativeThresholdsValue,sep=", ")) +
    facet_wrap(~Context)

}

##now start plotting

pragListenerLevel <- 1
defArtMeaning <- "bumford"
adj <- "big"
cmpHighScopeConstrualProbValue <- 1
posHighScopeConstrualProbValue <- 0
allowUninformativeThresholdsValue <- "disallow"

plot_result(pragListenerLevel,defArtMeaning,adj,cmpHighScopeConstrualProbValue,posHighScopeConstrualProbValue,allowUninformativeThresholdsValue)

allowUninformativeThresholdsValue <- "disallow"

adj <- "bigger"

plot_result(pragListenerLevel,defArtMeaning,adj,cmpHighScopeConstrualProbValue,posHighScopeConstrualProbValue,allowUninformativeThresholdsValue)

@

For comparison:

<<Plot-bumford-poshigh-cmphigh-justdisallow, echo=FALSE, cache=FALSE, warning=FALSE, message=FALSE, fig.width = 4.5, fig.height=2.7>>=

pragListenerLevel <- 1
defArtMeaning <- "bumford"
adj <- "big"
cmpHighScopeConstrualProbValue <- 1
posHighScopeConstrualProbValue <- 1
allowUninformativeThresholdsValue <- "disallow"

plot_result(pragListenerLevel,defArtMeaning,adj,cmpHighScopeConstrualProbValue,posHighScopeConstrualProbValue,allowUninformativeThresholdsValue)

@

\pagebreak
\subsection{Standard / low scope for pos}

<<Plot-standard-poslow, echo=FALSE, cache=FALSE, warning=FALSE, message=FALSE, fig.width = 4.5, fig.height=2.7>>=

#color blind palette
#cbPalette <- c("#009E73", "#CC79A7","#E69F00", "#56B4E9",  "#F0E442", "#0072B2", "#D55E00",  "#999999")

# "#009E73" is a nice green
# "#CC79A7" is dark pink
# "#E69F00" is gold
# "#56B4E9" is sky blue
# "#F0E442" is yellow
# "#0072B2" is a darker blue
# "#D55E00" is a burnt orange
# "#999999" is grey

#pink and blue
#myColors <- c("#56B4E9","lightblue","pink","#CC79A7")

#pink and teal
#myColors <- c("#009AA3","#00CFC6","pink","#CC79A7")

#orange/yellow and blue
myColors <- c("#2392E9","lightblue","#F0E442","#C44D00")

results$Container <- factor(results$Container,levels=c("box2","box1","bag1","bag2"))

#Create a custom fill scale 
#so that colors will be consistent even if not all levels are always present
names(myColors) <- levels(results$Container)
fillScale <- scale_fill_manual(name = "Container",values = myColors)

plot_result <- function (pragListenerLevel,
                         defArtMeaning,
                         adj,
                         cmpHighScopeConstrualProbValue,
                         posHighScopeConstrualProbValue,
                         allowUninformativeThresholdsValue) {
  gg_df <- subset(results, Adjective==adj & 
                    DefArtMeaning==defArtMeaning & 
                    Model=="haddock_model.wppl"  & 
                    ListenerLevel==pragListenerLevel & 
                    posHighScopeConstrualProb==posHighScopeConstrualProbValue & 
                    cmpHighScopeConstrualProb==cmpHighScopeConstrualProbValue &
                    allowUninformativeThresholds==allowUninformativeThresholdsValue)
  
  ggplot(gg_df, aes(x=Condition, y=Probability, fill=Container)) + 
    geom_bar(position="fill", stat="identity") +
    fillScale +
    theme_bw() +
    theme(axis.text.x = element_text(size=8),
          axis.text.y = element_text(size=10),  
          axis.title.x = element_text(size=10),
          axis.title.y = element_text(size=10),
          legend.title=element_text(size=10), 
          legend.text=element_text(size=10)
    ) +
    ylim(0,1) +
    xlab("Display Type") +
    ylab("Probability of Referent Choice") +
    ggtitle(paste("Model predictions for", adj),paste(defArtMeaning,paste0("L",pragListenerLevel),paste0("posHiScope:", posHighScopeConstrualProbValue),paste0("cmpHiScope:", cmpHighScopeConstrualProbValue),allowUninformativeThresholdsValue,sep=", ")) +
    facet_wrap(~Context)

}

##now start plotting

pragListenerLevel <- 1
defArtMeaning <- "standard"
adj <- "big"
cmpHighScopeConstrualProbValue <- 0
posHighScopeConstrualProbValue <- 0
allowUninformativeThresholdsValue <- "allow"

plot_result(pragListenerLevel,defArtMeaning,adj,cmpHighScopeConstrualProbValue,posHighScopeConstrualProbValue,allowUninformativeThresholdsValue)

allowUninformativeThresholdsValue <- "disallow"

plot_result(pragListenerLevel,defArtMeaning,adj,cmpHighScopeConstrualProbValue,posHighScopeConstrualProbValue,allowUninformativeThresholdsValue)

allowUninformativeThresholdsValue <- "lastresort"

plot_result(pragListenerLevel,defArtMeaning,adj,cmpHighScopeConstrualProbValue,posHighScopeConstrualProbValue,allowUninformativeThresholdsValue)

@

\pagebreak

\subsection{Standard / high scope for pos}

<<Plot-standard-poshigh, echo=FALSE, cache=FALSE, warning=FALSE, message=FALSE, fig.width = 4.5, fig.height=2.7>>=

pragListenerLevel <- 1
defArtMeaning <- "standard"
adj <- "big"
cmpHighScopeConstrualProbValue <- 0
posHighScopeConstrualProbValue <- 1
allowUninformativeThresholdsValue <- "allow"

plot_result(pragListenerLevel,defArtMeaning,adj,cmpHighScopeConstrualProbValue,posHighScopeConstrualProbValue,allowUninformativeThresholdsValue)

allowUninformativeThresholdsValue <- "disallow"
  
plot_result(pragListenerLevel,defArtMeaning,adj,cmpHighScopeConstrualProbValue,posHighScopeConstrualProbValue,allowUninformativeThresholdsValue)

allowUninformativeThresholdsValue <- "lastresort"

plot_result(pragListenerLevel,defArtMeaning,adj,cmpHighScopeConstrualProbValue,posHighScopeConstrualProbValue,allowUninformativeThresholdsValue)

@

\pagebreak

\subsection{Standard / low scope for cmp}

<<Plot-standard-cmplow, echo=FALSE, cache=FALSE, warning=FALSE, message=FALSE, fig.width = 4.5, fig.height=2.7>>=

pragListenerLevel <- 1
defArtMeaning <- "standard"
adj <- "bigger"
cmpHighScopeConstrualProbValue <- 0
posHighScopeConstrualProbValue <- 0
allowUninformativeThresholdsValue <- "allow"

plot_result(pragListenerLevel,defArtMeaning,adj,cmpHighScopeConstrualProbValue,posHighScopeConstrualProbValue,allowUninformativeThresholdsValue)

allowUninformativeThresholdsValue <- "disallow"
  
plot_result(pragListenerLevel,defArtMeaning,adj,cmpHighScopeConstrualProbValue,posHighScopeConstrualProbValue,allowUninformativeThresholdsValue)

allowUninformativeThresholdsValue <- "lastresort"

plot_result(pragListenerLevel,defArtMeaning,adj,cmpHighScopeConstrualProbValue,posHighScopeConstrualProbValue,allowUninformativeThresholdsValue)

@

\pagebreak

\subsection{Standard / high scope for cmp}

<<Plot-standard-cmphigh, echo=FALSE, cache=FALSE, warning=FALSE, message=FALSE, fig.width = 4.5, fig.height=2.7>>=

pragListenerLevel <- 1
defArtMeaning <- "standard"
adj <- "bigger"
cmpHighScopeConstrualProbValue <- 1
posHighScopeConstrualProbValue <- 0
allowUninformativeThresholdsValue <- "allow"

plot_result(pragListenerLevel,defArtMeaning,adj,cmpHighScopeConstrualProbValue,posHighScopeConstrualProbValue,allowUninformativeThresholdsValue)

allowUninformativeThresholdsValue <- "disallow"
  
plot_result(pragListenerLevel,defArtMeaning,adj,cmpHighScopeConstrualProbValue,posHighScopeConstrualProbValue,allowUninformativeThresholdsValue)

allowUninformativeThresholdsValue <- "lastresort"

plot_result(pragListenerLevel,defArtMeaning,adj,cmpHighScopeConstrualProbValue,posHighScopeConstrualProbValue,allowUninformativeThresholdsValue)

@


\pagebreak
\subsection{Bumford / low scope for pos + low scope for cmp}

\setlength\parindent{0em}
<<Plot-bumford-poslow-cmplow, echo=FALSE, cache=FALSE, warning=FALSE, message=FALSE, fig.width = 4.5, fig.height=2.7>>=

pragListenerLevel <- 1
defArtMeaning <- "bumford"
adj <- "big"
cmpHighScopeConstrualProbValue <- 0
posHighScopeConstrualProbValue <- 0
allowUninformativeThresholdsValue <- "allow"

plot_result(pragListenerLevel,defArtMeaning,adj,cmpHighScopeConstrualProbValue,posHighScopeConstrualProbValue,allowUninformativeThresholdsValue)

allowUninformativeThresholdsValue <- "disallow"

plot_result(pragListenerLevel,defArtMeaning,adj,cmpHighScopeConstrualProbValue,posHighScopeConstrualProbValue,allowUninformativeThresholdsValue)

allowUninformativeThresholdsValue <- "lastresort"

plot_result(pragListenerLevel,defArtMeaning,adj,cmpHighScopeConstrualProbValue,posHighScopeConstrualProbValue,allowUninformativeThresholdsValue)

@

\pagebreak
\subsection{Bumford / low scope for pos + high scope for cmp}

\setlength\parindent{0em}
<<Plot-bumford-poslow-cmphigh, echo=FALSE, cache=FALSE, warning=FALSE, message=FALSE, fig.width = 4.5, fig.height=2.7>>=

pragListenerLevel <- 1
defArtMeaning <- "bumford"
adj <- "big"
cmpHighScopeConstrualProbValue <- 1
posHighScopeConstrualProbValue <- 0
allowUninformativeThresholdsValue <- "allow"

plot_result(pragListenerLevel,defArtMeaning,adj,cmpHighScopeConstrualProbValue,posHighScopeConstrualProbValue,allowUninformativeThresholdsValue)

allowUninformativeThresholdsValue <- "disallow"

plot_result(pragListenerLevel,defArtMeaning,adj,cmpHighScopeConstrualProbValue,posHighScopeConstrualProbValue,allowUninformativeThresholdsValue)

allowUninformativeThresholdsValue <- "lastresort"

plot_result(pragListenerLevel,defArtMeaning,adj,cmpHighScopeConstrualProbValue,posHighScopeConstrualProbValue,allowUninformativeThresholdsValue)

@

\pagebreak

\subsection{Bumford / high scope for pos + low scope for cmp}

<<Plot-bumford-poshigh-cmplow, echo=FALSE, cache=FALSE, warning=FALSE, message=FALSE, fig.width = 4.5, fig.height=2.7>>=

pragListenerLevel <- 1
defArtMeaning <- "bumford"
adj <- "big"
cmpHighScopeConstrualProbValue <- 0
posHighScopeConstrualProbValue <- 1
allowUninformativeThresholdsValue <- "allow"

plot_result(pragListenerLevel,defArtMeaning,adj,cmpHighScopeConstrualProbValue,posHighScopeConstrualProbValue,allowUninformativeThresholdsValue)

allowUninformativeThresholdsValue <- "disallow"
  
plot_result(pragListenerLevel,defArtMeaning,adj,cmpHighScopeConstrualProbValue,posHighScopeConstrualProbValue,allowUninformativeThresholdsValue)

allowUninformativeThresholdsValue <- "lastresort"

plot_result(pragListenerLevel,defArtMeaning,adj,cmpHighScopeConstrualProbValue,posHighScopeConstrualProbValue,allowUninformativeThresholdsValue)

@


\pagebreak

\subsection{Bumford / high scope for pos + high scope for cmp}

<<Plot-bumford-poshigh-cmphigh, echo=FALSE, cache=FALSE, warning=FALSE, message=FALSE, fig.width = 4.5, fig.height=2.7>>=

pragListenerLevel <- 1
defArtMeaning <- "bumford"
adj <- "big"
cmpHighScopeConstrualProbValue <- 1
posHighScopeConstrualProbValue <- 1
allowUninformativeThresholdsValue <- "allow"

plot_result(pragListenerLevel,defArtMeaning,adj,cmpHighScopeConstrualProbValue,posHighScopeConstrualProbValue,allowUninformativeThresholdsValue)

allowUninformativeThresholdsValue <- "disallow"
  
plot_result(pragListenerLevel,defArtMeaning,adj,cmpHighScopeConstrualProbValue,posHighScopeConstrualProbValue,allowUninformativeThresholdsValue)

allowUninformativeThresholdsValue <- "lastresort"

plot_result(pragListenerLevel,defArtMeaning,adj,cmpHighScopeConstrualProbValue,posHighScopeConstrualProbValue,allowUninformativeThresholdsValue)

@


\pagebreak

\subsection{Bumford / low scope for cmp}

<<Plot-bumford-cmplow, echo=FALSE, cache=FALSE, warning=FALSE, message=FALSE, fig.width = 4.5, fig.height=2.7>>=

pragListenerLevel <- 1
defArtMeaning <- "bumford"
adj <- "bigger"
cmpHighScopeConstrualProbValue <- 0
posHighScopeConstrualProbValue <- 0
allowUninformativeThresholdsValue <- "allow"

plot_result(pragListenerLevel,defArtMeaning,adj,cmpHighScopeConstrualProbValue,posHighScopeConstrualProbValue,allowUninformativeThresholdsValue)

allowUninformativeThresholdsValue <- "disallow"
  
plot_result(pragListenerLevel,defArtMeaning,adj,cmpHighScopeConstrualProbValue,posHighScopeConstrualProbValue,allowUninformativeThresholdsValue)

allowUninformativeThresholdsValue <- "lastresort"

plot_result(pragListenerLevel,defArtMeaning,adj,cmpHighScopeConstrualProbValue,posHighScopeConstrualProbValue,allowUninformativeThresholdsValue)

@

\pagebreak

\subsection{Bumford / high scope for cmp}

<<Plot-bumford-cmphigh, echo=FALSE, cache=FALSE, warning=FALSE, message=FALSE, fig.width = 4.5, fig.height=2.7>>=

pragListenerLevel <- 1
defArtMeaning <- "bumford"
adj <- "bigger"
cmpHighScopeConstrualProbValue <- 1
posHighScopeConstrualProbValue <- 0
allowUninformativeThresholdsValue <- "allow"

plot_result(pragListenerLevel,defArtMeaning,adj,cmpHighScopeConstrualProbValue,posHighScopeConstrualProbValue,allowUninformativeThresholdsValue)

allowUninformativeThresholdsValue <- "disallow"
  
plot_result(pragListenerLevel,defArtMeaning,adj,cmpHighScopeConstrualProbValue,posHighScopeConstrualProbValue,allowUninformativeThresholdsValue)

allowUninformativeThresholdsValue <- "lastresort"

plot_result(pragListenerLevel,defArtMeaning,adj,cmpHighScopeConstrualProbValue,posHighScopeConstrualProbValue,allowUninformativeThresholdsValue)

@



\end{document}