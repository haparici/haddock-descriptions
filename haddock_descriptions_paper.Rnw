\documentclass[letterpaper, 12pt]{article}
%\usepackage{liatex85}
\usepackage{etex}
\usepackage{geometry}                % See geometry.pdf to learn the layout options. There are lots.
\geometry{letterpaper}                   % ... or a4paper or a5paper or ... 
\usepackage{amsmath,amsfonts, amssymb, latexsym, mathtools,mathrsfs, fancyhdr,theorem,  pifont, setspace, verbatim,  qtree, lscape, tipa,  hyperref, wasysym, natbib,soul, minibox, lipsum, setspace, amssymb, color, multirow, multicol, soul,geometry,graphicx, wrapfig,gb4e,booktabs,stmaryrd}
\usepackage[T1]{fontenc}
\usepackage{times}
%\usepackage[backend=bibtex, sorting=none]{biblatex}
\geometry{hmargin={1in,1in},vmargin={1in,1in}}

\definecolor{Red}{RGB}{255,0,0}
\newcommand{\red}[1]{\textcolor{Red}{#1}}
\newcommand{\ha}[1]{\textcolor{Red}{[ha: #1]}} 


 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
 %%%% Some math symbols used in the text
 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
 % Format 


\def\>{\rangle}
\def\<{\langle}

\def\true{1}
\def\given{\,|\,}

\def\valueof#1{\llbracket #1\rrbracket}


\def\ol#1{\textit{#1}}

\def\valueof#1{\ensuremath{\llbracket #1\rrbracket}}


\title{Context-Sensitivity in Haddock Descriptions}
\author{Helena, Roger, Liz}


\begin{document}

\maketitle

<<Setup, include=FALSE>>=

# Import libraries

#General

require(knitr)
#library(devtools)

#Stats
require(lmerTest)
#devtools::install_github("paul-buerkner/brms")
require("rstan") 
require(brms)
require(broom)

#Plotting
#require(Rmisc)
require(ggplot2)
require(tidyboot)
#devtools::install_github("mikabr/ggpirate")
require(ggpirate)

#Running models
require(ggm)
require(ggpubr)
require(rlist)
require(RJSONIO)
require("rwebppl")
#to install rwebppl
#install.packages("devtools")
#devtools::install_github("mhtess/rwebppl")

# Global settings for chunks
opts_chunk$set(echo = F, message = F, warning = F, cache=T)
#fig.path <- "../../" in case we end up needing it

#Repo
#https://github.com/haparici/haddock-descriptions
#Add the rest of the libraries here

@

<<Model_Parameters_Variables, echo=FALSE, cache=TRUE,warning=FALSE, message=FALSE, fig.width = 13,fig.height=3>>=

## Visuals Master ##
refs_json <- '[
  {"Animal": "rabbit", "Container": "bag", "Size": 1}
  , {"Animal": "rabbit", "Container": "bag", "Size": 2}
  , {"Animal": "frog", "Container": "bag", "Size": 3}
  , {"Animal": "frog", "Container": "box", "Size": 1}
  , {"Animal": "rabbit", "Container": "box", "Size": 2}
  , {"Animal": "frog", "Container": "basket", "Size": 3}
  , {"Animal": "rabbit", "Container": "box", "Size": 1}
  ]'

refs <- fromJSON(refs_json)
refs <- do.call("rbind", refs)
refs <- data.frame(refs)

## Visual Logical Constructor ##
conds_idx <- list(
  c(TRUE, TRUE, TRUE, TRUE, TRUE, FALSE, FALSE)
  , c(TRUE, TRUE, FALSE, TRUE, TRUE, TRUE, FALSE)
  , c(TRUE, TRUE, TRUE, FALSE, TRUE, FALSE, TRUE)
)

get_visuals <- function(refs, conds_idx, i){
  
  cond_idx <- unlist(conds_idx[i])
  visual <- refs[cond_idx, ]
  
  return(visual)
  
}

## Descriptions ##
#modifiers <- c('smaller', 'small', 'big', 'bigger', 'none')
modifiers <- c('small', 'big', 'none')
get_descriptions <- function(visual, modifiers) {
  
  visual_unique <- unique(visual[, c("Animal", "Container")])
  
  descs <- list()
  for (ref in 1:nrow(visual_unique)) {
    for (mod in modifiers) {
      animal <- visual_unique[ref, "Animal"]
      container <- visual_unique[ref, "Container"]
      desc = list(animal, mod, container)
      descs <- list.append(descs, unlist(desc))
    }
  }
  desc <- list("none", "none", "none")
  descs <- list.append(descs, unlist(desc))
  return(descs)
}

get_costs <- function(descs) {
  
  costs <- list()
  columns <- list()
  
  for (i in 1:length(descs)) {
    
    desc <- unlist(descs[i])
    desc_str <- paste(desc[1], desc[2], desc[3])
    adjective <- desc[2]
    tail <- substr(adjective, nchar(adjective) - 1, nchar(adjective))
    
    if (tail == "er") {
      
      cost <- 1.5
      
      
    } else if (adjective %in% c("small", "big")) {
      
      cost <- 1
      
    } else if (adjective == "none") {
      
      cost <- 0.5
      
    } else {
      
      cost <- 0
      
    }
    costs <- list.append(costs, cost)
    columns <- list.append(columns, desc_str)
  }
  costs <- data.frame(costs)
  colnames(costs) <- unlist(columns)
  
  return(costs)
}

    
##Random Variables##

pos<-list(c("rabbit", "big", "bag"),c("rabbit", "big", "box"))
cmp<-list(c("rabbit", "bigger", "bag"),c("rabbit", "bigger", "box"))

#randomVariables<-list(pos,cmp)
randomVariables<-list(pos)
#randomVariables<-list(cmp)

execute_model <- function(randomVariable, cond, model, context, defArt, package, gamma, costCoefficient,highScopeConstrualProb) {
  
  # Model
  visuals <- get_visuals(refs, conds_idx, cond)
  descs <- get_descriptions(visuals, modifiers)
  costs <- get_costs(descs)
  
  model_data <- list(randomVariable, visuals, descs, costs, context, defArt, gamma, costCoefficient,highScopeConstrualProb)
  
  model <- webppl(program_file=model, 
                  data = model_data, 
                  data_var = "model_data", 
                  package=package)
  
  return(model)
  
}



@


<<Model_Main, echo=FALSE, cache=TRUE, warning=FALSE, message=FALSE, fig.width = 13, fig.height=3>>=

## Main ##
# Calling Parameters 

conds <- c(1, 2, 3)
contexts <- c("cco","no-cc")
defArtMeanings <- c("bumford", "standard")


#models <- c("haddock_model.wppl","haddock_model_pragmaticListener2.wppl")
models <- c("haddock_model.wppl") #,"haddock_model_pragmaticListener2.wppl")
#gamma is probability that any given referent will be included in the context
gamma <- .9
#higher cost coefficient increases informativity effect
costCoefficient <- 3
highScopeConstrualProb <- 0.5

test_result <- execute_model(pos, 1, "haddock_model.wppl","cc","bumford",".",gamma,costCoefficient,highScopeConstrualProb)



# Execute Model
results <- data.frame()

for(defArtMeaning in defArtMeanings) { 
  for (context in contexts) {
    for (randomVariable in randomVariables) {
      for (cond in conds) {
        for (model in models) {

          result <- execute_model(randomVariable, cond, model, context, defArtMeaning,".",gamma,costCoefficient,highScopeConstrualProb)

          result$Adjective <- randomVariable[[1]][2]
          result$defArtMeaning <- defArtMeaning
          result$Context <- context
          result$Condition <- cond
          result$Model <- model
          results <- rbind(results, result)
           #print(paste("Processing adjective"
           #       , randomVariable[[1]][2]
           #       , "for context"
          #        , context
          #        , "for defArtMeaning"
          #        , defArtMeaning
          #        , "for condition"
          #        , cond
          #        , "with model"
          #        , model))
        }
      }
    }
  }
}

colnames(results) <- c(
  "Animal"
  , "Container"
  , "Size"
  , "Probability"
  , "Adjective"
  , "DefArtMeaning"
  , "Context"
  , "Condition"
  , "Model")

#results

@

\section{Introduction}

%The gradable adjective {\em big} and the definite article {\em the} are both context-sensitive expressions. 
%Something that is big in one context might not be big in another. 
%Whether or not it is felicitous to use the expression {\em the rabbit} depends on how many rabbits are in the context. 
%This paper investigates the relationship between these two manifestations of context-sensitivity.

Suppose there are three hats, two rabbits, a frog, and a calculator on a table before you. 
One of the rabbits is in one of the hats, and the other two hats contain the frog and the calculator, respectively.
You are instructed to point to {\em the hat}. 
You might feel a bit squeamish, because the uniqueness requirement of the definite article is not satisfied in this context. 
But asked to point to {\em the rabbit in the hat}, you would confidently pick out the rabbit in {\em the hat that has a rabbit in it} (barring unusual circumstances). 
Such nested definite descriptions, in which the inner definite seems to lose its uniqueness requirement, are called {\em Haddock descriptions}.%
\footnote{Fun fact: The same phenomenon can occur when multiple definites are embedded within another. \citet{horacek:1995} observed that {\em the table with the apple and the banana} is felicitous in a context with three tables, one with one apple and one banana (the referent), one with an apple and a mug, and one with a banana and a bowl.}


\citet{haddock:1987} characterized the task of the listener when presented with such descriptions as a {\em constraint satisfaction problem} of the kind studied in Artificial Intelligence: 
Find the unique $x$ such that (i) $x$ is a rabbit; (ii) $y$ is a hat; and (iii) $x$ is in $y$. \citet{vaneijck:1993} cast the same idea in dynamic semantics. 
The description is felicitous if a unique such $x$ can be found. 
But neither \citeauthor{haddock:1987} nor \citeauthor{vaneijck:1993} specified the process by which a listener can determine that this is the problem before her, and in principle, these constraints could be derived either semantically or pragmatically.

According to \citet{bumford:2017}, the uniqueness requirement of the inner definite in {\em the rabbit in a hat} can be loosened through a scope-taking mechanism that lets the uniqueness requirement of the definite article take scope above {\em rabbit}. 
In that scope position, what the uniqueness requirement demands is that there be no more than one {\em hat containing a rabbit}, even if there is more than one {\em hat} simpliciter.
On this semantic approach, the loosening of the uniqueness requirement does not involve elimination of certain referents from consideration through pragmatic reasoning.

But it is known that the process of identifying a referent for {\em unembedded} definite descriptions involves a flexible conception of uniqueness, on which entities that meet the description but cannot possibly serve as the intended referent are excluded from the count. 
Given the instruction {\em Put the cube inside the can}, listeners easily identify the referent of {\em the can} as the one that is large enough to hold the cube in question \citep{chambers+al:2002}, even if there are multiple cans in the display. 
These experimental findings bolster the observation by \citet{stone+webber:1998} that in the kind of scenario we began with, it would be felicitous to utter either {\em Remove the rabbit from the hat} or {\em Bill put the rabbit in the hat}.
Given this, the disappearance of the uniqueness requirement for the inner definite of a Haddock description might reasonably be seen as an instance of the same phenomenon, involving commonsense reasoning to exclude certain potential referents from consideration. One particular way of caching this out, suggested by \citet{muhlstein+al:2015}, is that the listener reasons probabilistically about the context relative to which a definite description should be interpreted.%

If the loosening of the uniqueness requirement for a definite description is due to tightening of the context, then we might expect other context-sensitive expressions in the embedded noun phrase to change their interpretation accordinngly. The question that this paper aims to address is whether or not such a phenomenon occurs, specifically with gradable adjectives.

To that end, the present paper investigates the interpretation of gradable adjectives embedded inside Haddock descriptions, as in {\em the rabbit in the big hat}.
Given that the relevant set of hats for the purpose of the definite description contains only ones with rabbits in them, does that restrict what hats are included in the comparison class for {\em big}?
{\em Ceteris paribus,} the semantic approach predicts that the comparison class for {\em big} should not be restricted to rabbit-containing hats, as there is no context narrowing on this view.
On the other hand, if Haddock descriptions involve context narrowing, then, depending on how this idea is implemented, we might expect that the comparison class for {\em big} should be restricted to rabbit-containing hats.

Our experiments show that the comparison class for {\em big} includes all hats, not just the ones containing rabbits. 
This is straightforwardly predicted under the semantic approach to Haddock descriptions, and places some constraints on how the pragmatic approach should work. 
If the loosening of the uniqueness requirement for definite articles is due to context-narrowing, this narrowing is not so powerful and all-encompassing that it affects comparison classes for gradable adjectives.



\section{Experiment}


Participants heard auditory instructions while looking at visual displays consisting of five images arranged in a circle. In experimental trials, the auditory instruction consisted of a request of the form `{\em Click on the rabbit in the big} [{\em masked}]', where the second NP had been masked with quite static noise. 
Each display contained two possible referents compatible with the truncated description (e.g., a rabbit in a medium bag and a rabbit in a medium box in Figure \ref{displays}). 
Given this ambiguity, participants were instructed to click on the referent that best matched the available linguistic content of the utterance given the visual display.

\begin{figure}[h]
\centering
    \includegraphics[width=11cm]{images/contexts.png}
  \caption{Visual Displays tested in Experiment 1. The labeling in this picture is a bit misleading in that it codes each of the           contexts w.r.t. the positive form adjective, not the comparative. However, we seem to be observing slight competitor            effects for the comparative as well, so this labeling might turn out to be the correct one. Also, do we want to use             this labeling?}
\label{displays}
\end{figure}

The experimental manipulations targetted the content of the auditory instructions, as well as the features of the visual displays. 
The first manipulated factor was the adjective type used to modify the masked NP in the auditory instruction.
This modifier always consisted of the relative adjective {\em big} in either its positive ({\em big}) or comparative form ({\em bigger}). 
Second, we manipulated the visual properties of the displays with respect to whether they contained a competitor object that was in the same container-type as one of the potential referents of the truncated description (i.e., a bag or a box). However, this competitor was not a possible referent of the global description, since it consisted of an animal that could not be described by the first NP in the description (e.g., a frog inside a bag). 
Despite not being compatible with the global instruction, this referent acted as a competitor because the size of its container was always greater than the biggest rabbit-containing bag/box in the display.
Thus, the competitor's container was the most appropriate referent of the nested definite description if interpreted in isolation (see Context 1, or leftmost pannel, in Figure \ref{displays}). 
The second visual manipulation determined whether the smallest box/bag in the display also contained a rabbit in it (e.g., a rabbit vs. a frog in the smallest box. See Contexts 1-2 vs. 3 respectively in Figure \ref{displays}). 
This manipulation determined whether the use of the adjective in the auditory instruction was informative, i.e., whether the mention of the adjective was required for successful reference resolution. 
For instance, given Context 1 in Figure \ref{displays}, where the smallest box in the display contains a frog and the smallest bag contains a rabbit, the adjective in the instruction `{\em Click on the rabbit in the big} [masked]' is informative on the bag resolution, but superfluous on the box resolution, since in the latter case the shorter adjectiveless description `{\em Click on the rabbit in the} [masked]' would have sufficed to properly identify the referent in the medium box, but not the referent in the medium bag.\footnote{Once we settle on a meaning for the comparative, we should also be specific about how this applies to the comparative.}
The experimental manipulations described above were tested through the three visual contexts exemplified in Figure \ref{displays}. 

\noindent
{\bf ToDo:} Add information about fillers. Do we want to include Exp1?
%Norming study?



%\subsection{Predictions}

%\noindent
%\textbf{Predictions w.r.t. CC calculation}

%\noindent
%\textbf{Predictions w.r.t. definite article interpretation}


\subsection{Results}

{\textbf{[this section is outdated]}

Experimental results are plotted in Figure \ref{results}, which plots for each of the three contexts tested the probability of bag resolution (proportion of clicks to the rabbit in the medium bag vs. clicks on the the rabbit in the medium box). 
The yellow line corresponds to chance after correcting for responses that did not correspond to any of these two objects (a total of X).


%Do we want to regenerate this plot with bootstrap CI's?

%Data from xx were discarded either because xxx (N) or because the reported not to be native speakers of American English (XX). After xxx a total of XX participants.

\begin{figure}
\centering
<<results1, echo=FALSE, cache=TRUE, warning=FALSE, message=FALSE, fig.width = 4, fig.height=4.5>>=

data<-read.csv("exp2-m1-p1-p2-p3b-cleaned.csv", header=TRUE) #225 participants

data$displaytype1[data$displaytype=="abs-rel"]= "Context 1"
data$displaytype1[data$displaytype=="abs-both"]= "Context 2"
data$displaytype1[data$displaytype=="both-rel"]= "Context 3"

data$adjtype2[data$adjtype=="pos"]= "big"
data$adjtype2[data$adjtype=="cmp"]= "bigger"

data$stim.version<-paste(data$stimnum,data$version,sep="-")

data$stim.version<-as.factor(data$stim.version)
data$target<-as.numeric(as.character(data$target))

df.data.item <- data %>%
  group_by(displaytype1, adjtype2, stimnum) %>%
  tidyboot_mean(column = target)

df.data.general <- data %>%
  group_by(displaytype1, adjtype2) %>%
  tidyboot_mean(column = target)

plot.general<-df.data.general %>%
  ggplot(., aes( x = displaytype1, y = mean, fill = adjtype2))+
  #theme_black()+
  geom_hline(yintercept = 0.5, lty = 2, alpha = 0.5, color = 'black')+
  geom_col(position = position_dodge(0.8),
           aes(y = mean),
           width = 0.8,
           alpha = 0.4,
           color = 'black')+
  geom_point(data = df.data.item,
             position = position_jitterdodge(),
             inherit.aes = F, aes(x = displaytype1, y = mean, color = adjtype2),
             alpha = 0.25)+
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper),
              position = position_dodge(0.8), size = 1.2,
              color = 'black')+ 
  ylab("Probability of bag resolution")+
  #facet_wrap(~ me) +
  scale_y_continuous(limits = c(0, 1), breaks = c(0, 0.5, 1))+
  scale_fill_manual(values = c("#009E73", "#CC79A7"))+
  scale_color_manual(values = c("#009E73", "#CC79A7"))+
  xlab("")+
  #facet_wrap(~me_status, scales = 'free_x')+
  #guides(fill = guide_legend(title = "Question"),
  #       color = guide_legend(title = "Question"))+
  theme(axis.text.x = element_text(angle = 20, vjust = 0.55, hjust = 0.5),
        legend.position = "bottom")
plot.general
@
\caption{Results for Experiment 1. Proportion of responses corresponding to the bag resolution vs. box resolution in each of the six conditions tested.}
\label{results}
\end{figure}

\noindent
Results for subset of data corresponding to the first two conditions (Contexts 1 and 2):
posterior mean estimate and 95$\%$ credible interval for the interaction adjective type x display type: $\beta$ = $-1.25[-2.63, 0.02]$

<<Stats, echo=FALSE, cache=TRUE, warning=FALSE, message=FALSE, fig.width = 13, fig.height=3>>=

require(dplyr)
require(lmerTest)
#devtools::install_github("paul-buerkner/brms")
require("rstan") 
require(brms)
require(broom)


#merge stim and version colum
data$stim.version<-paste(data$stim, "", data$version)

#remove both-rel condition (context 3) to check relevant interaction

data.interaction = subset(data, displaytype!="both-rel")

#Column we are trying to predict data$target1

#Different labels we've used for the different kinds of displays
#"abs-rel" same/diff+competitor, aka context 1
#"abs-both" same/diff-competitor, aka context 2
#"both-rel" same/same+competitor, aka context 3


### Bayesian analysis ###
#for model comparison loo()
#data.interaction2 comares contexts 1 and 2
#https://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup


model1<- brm(
  formula = target ~ adjtype*displaytype +
    (1+adjtype*displaytype | usernum)+(1+adjtype*displaytype | stim),
    data = data.interaction,
    family = "bernoulli",
    control=list(adapt_delta=0.99),
    iter = 2000,
    chains = 4,
    cores = 4,
)


model2<- brm(
  formula = target ~ adjtype*displaytype +
    (1+adjtype*displaytype | usernum)+(1+adjtype*displaytype | stim.version),
    data = data.interaction,
    family = "bernoulli",
    control=list(adapt_delta=0.99),
    iter = 2000,
    chains = 4,
    cores = 4,
)



#model1
#model2



@


\subsection{Discussion}

\section{Semantic Assumptions}


\subsection{Positive (\ol{big})}

Let us begin by discussing our semantics for positive form gradable adjectives like \ol{big}. We assume that such expressions are evaluated relative to a given threshold $\theta$, which must be exceeded in order for the gradable adjective to hold of a given referent. We assume furthermore that what counts as `big' differs depending on the type of object whose size is in question. We therefore have different thresholds for different types of objects. $\theta(\ol{bag})$ is the threshold for bags, for example.

Writing `the denotation of $\alpha$ relative to context $C$ and threshold $\theta$' as $\valueof{\alpha}^{\theta,C}$, we will say that $\valueof{\alpha}^{\theta,C}(r) = \true$ if referent $r$ falls under description $\alpha$, relative to $\theta$ and $C$.
What it takes for $b$ to count as a \ol{big bag}, relative to threshold $\theta$ and context $C$, is the following:
\begin{enumerate}
  \item $b$ is in $C$
  \item $b$ is a bag:\\
  $\valueof{\ol{bag}}^{\theta,C}(b) =\true$
  \item $b$'s size exceeds the threshold required for bags to count as \ol{big}:\\
  $\textsf{size}(b)>\theta$
\end{enumerate}
Thus if all of the above conditions are met, then $\valueof{\ol{big bag}}^{\theta,C}(b)=\true$.

\subsection{Definite article}

Now let us consider how to analyze {\em the big bag}.
We entertain two alternative analyses of the definite article {\em the}. 
On what we will refer to as the \textbf{standard analysis}, the definite article carries a presupposition of uniqueness relative to some given context.
Thus, \ol{the big bag} denotes the unique bag in some given context $C$ that counts as `big', as determined by whether or not it exceeds a given threshold $\theta$.  To serve as the referent for a definite description of the form \ol{the NP}, a given referent $r$ must satisfy the following conditions:
\begin{enumerate}
\item $r$ satisfies NP, relative to $\theta$ and $C$:\\
$\valueof{\textnormal{NP}}^{\theta,C}(r) = \true$ 
\item No distinct $r'\in C$ satsifies NP, relative to $\theta$ and $C$.
\end{enumerate}

By extension, \ol{the rabbit in the big bag} denotes the unique rabbit (in some given context $C$) that is in $b$, 
where $b$ is the unique bag in $C$ that is big, according to a given threshold $\theta$.
Thus, the non-trivial conditions that a given referent $r$ must satisfy in order to fall under the description \ol{the rabbit in the NP}, 
relative to context $C$ and threshold $\theta$, 
are the following:
\begin{enumerate}
    \item $r$ is a rabbit in $C$:\\
     $\valueof{\ol{rabbit}}^{\theta,C}(r) =\true$
    \item $r$ is in some $b$ such that:\\
    $\valueof{\ol{in}}^{\theta,C}(b)(r) =\true$, where:
    \begin{itemize}
        \item $b$ satisfies \ol{NP}, relative to $\theta$ and $C$:\\
        $\valueof{\ol{NP}}^{C,\theta}(b) = \true$ 
        \item No distinct $b'$  satisfies \ol{NP}, relative to $\theta$ and $C$
    \end{itemize}
    \item No distinct $r' \in C$ meets conditions 1-2.
\end{enumerate}
%
Thus uniqueness is enforced at both the inner and outer layers of the description, relative to a given context.

Another analysis of definite descriptions that we will entertain is what we will call \textbf{Bumford's}. \citet{bumford:2017} offers a semantic analysis of Haddock descriptions, building on an analysis of the definite article in which the existence and uniqueness components may enter the composition at different stages, with other material intervening. 
The existence component ensures that a discourse referent is associated with the nominal. 
The uniqueness component ensures that the discourse referent cannot be mapped to more than one entity, in light of the restrictions that have been put on it. The restrictions put on the discourse referent may not be limited to the descriptive material within the definite description; 
surrounding descriptive material may accumulate before uniqueness is checked. In particular, the uniqueness component of the inner definite in an expression of the form \ol{the rabbit in the big bag} may take scope above \ol{rabbit}. 
Interpreted with such high scope, the definite article serves merely to ensure that there is no more than one rabbit/big-bag pair such that the rabbit is in the big bag. 
As far as the definite article is concerned, there may well be another big bag, as long as it doesn't contain a rabbit. 
In other words, this definite article does not require uniqueness with respect to the property `big bag'. 

Under a high-scope construal of the uniqueness component of the definite article,
is \ol{rabbit in the big bag} synonymous with \ol{rabbit in a big bag}? Almost, but not entirely. The difference in meaning would only be visible in a scenario in which a rabbits was in multiple bags -- something very hard to imagine. But consider an example like \ol{the singer with the gold bracelet}. Even on a high scope construal, this description could only be true of a singer that is wearing a single bracelet, whereas \ol{the singer with a gold bracelet} could truthfully hold of a singer that has multiple bracelets (although pragmatics would suggest that he or she was only wearing one). As this kind of situation (e.g.\ one rabbit - multiple bags) does not occur in our experimental stimuli, the difference effectively disappears in our setting. 

Thus, under this construal, the non-trivial conditions that a given referent $r$ must satisfy in order to fall under the description \ol{the rabbit in the NP}, 
relative to context $C$ and threshold $\theta$, 
are just the following:
\begin{enumerate}
    \item $r$ is a rabbit in $C$:\\
     $\valueof{\ol{rabbit}}^{\theta,C}(r) =\true$
    \item $r$ is in some $b$ such that:\\
    $\valueof{\ol{in}}^{\theta,C}(b)(r) =\true$, where:
    \begin{itemize}
      \item $\valueof{\ol{NP}}^{C,\theta}(b) = \true$
    \end{itemize}
    \item No distinct $r' \in C$ meets conditions 1-2.
\end{enumerate}
The last condition is the contribution of the outer definite article, which we assume is interpreted without any scope-taking placing additional constraints on the rabbit. 
When these conditions are met, $\valueof{\ol{the rabbit in the NP}}^{\theta,C}(r) =\true$, on Bumford's analysis. The main difference between Bumford's analysis and the standard analysis is what constraints are put on $b$, whether it just has to satisfy the descriptive content of the inner NP (as on Bumford's analysis), or whether it must furthermore be the only entity in $C$ that does so.

\subsection{Comparative}

We will consider two alternative analyses of the comparative \ol{bigger} corresponding to the he well-known distinction between {\em relative} and {\em absolute} readings of superlatives \citep{szabolcsi:1986,heim:1999}.
Although the distinction has mainly been discussed in regards to superlatives, it also applies to comparatives, as argued in the appendix.
Just as {\em the highest shelf} in {\em the book on the highest shelf} can refer to either the absolutely highest shelf (absolute reading) or the highest shelf {\em that a book is on} (relative reading), {\em the higher shelf} in {\em the book on the higher shelf} can refer to the higher of two shelves (absolute reading), or it can refer to the higher of the two shelves {\em that a book is on} (relative reading).

According to Bumford, superlatives can be interpreted either high, with the determiner, or low, where the positive form adjective is interpreted. A low scope position corresponds to an absolute interpretation. Note that in principle, the superlative can be interpreted low even if the determiner is interpreted high. On a low interpretation of the superlative combined with a high interpretation of the definite article, \ol{the rabbit in the biggest bag} is true of $r$ if and only if:
%
\begin{enumerate}
    \item $r$ is a rabbit in $C$:\\
     $\valueof{\ol{rabbit}}^{\theta,C}(b) =\true$
    \item $r$ is in some $b$ such that:\\
        $\valueof{\ol{in}}^{\theta,C}(r,b) =\true$ where
        \begin{itemize}
    \item $b$ is a bag in $C$:\\
     $\valueof{\ol{bag}}^{\theta,C}(b) =\true$
    \item $b$ is bigger than any other bag in $C$:\\
    For all $b'$ such that $\valueof{\ol{bag}}^{\theta,C}(b') =\true$:
    \textsf{size}($b$) $>$ \textsf{size}($b'$)
    \end{itemize}
\item No referent distinct from $r$ in $C$ meets conditions 1-2.
\end{enumerate}

On a high interpretation of the superlative, combined with a high interpretation of the definite article, \ol{the rabbit in the biggest bag} is true of $r$ if and only if it is a rabbit in a bag that is bigger than any other {\em rabbit-containing} bag:
%
\begin{enumerate}
    \item $r$ is a rabbit in $C$:\\
     $\valueof{\ol{rabbit}}^{\theta,C}(b) =\true$
    \item $r$ is in some $b$:\\
        $\valueof{\ol{in}}^{\theta,C}(r,b) =\true$ where:
        \begin{itemize}
          \item $b$ is a bag in $C$:\\
          $\valueof{\ol{bag}}^{\theta,C}(b) =\true$
          \item $b$ is bigger than any other rabbit-containing bag in $C$:\\
          For all $b'$ such that:
            \begin{itemize}
              \item $\valueof{\ol{bag}}^{\theta,C}(b') =\true$
              \item and there is some $r'$ such that:
                \begin{itemize}
                  \item $\valueof{\ol{rabbit}}^{\theta,C}(r')$
                  \item $\valueof{\ol{in}}^{\theta,C}(r',b')$
                \end{itemize}
            \end{itemize}
          \textsf{size}($b$) $>$ \textsf{size}($b'$)
        \end{itemize}
\item No referent distinct from $r$ in $C$ meets conditions 1-2.
\end{enumerate}

We assume that the same two possibilities are available for comparatives, and  furthermore that comparatives are only defined when the comparison class contains exactly two elements.%
\footnote{%
It is possible to find attestations of {\em the bigger of the three}, but there are very few attestations of {\em the bigger of the $n$} for larger $n$s, and it appears that {\em the larger of the three} is licensed only in contexts where there are two sizes, one larger than the other, and the referent of {\em the larger of the three} bears the larger of the two sizes, while the other two bear the smaller of the two sizes. 
To account for such cases, we could modify our assumptions so that {\em larger N} means something like {\em larger of the Ns}, where the comparison class consists of two pluralities of Ns, each with their own aggregate size. 
Because we never had multiple Ns whose sizes could be treated as the same in our experiments, we ignore this wrinkle.%
}
The low interpretation of the comparative, then, combined with the high interpretation of the definite article is as follows, for the expression \ol{the rabbit in the bigger bag}:
%
\begin{enumerate}
    \item $r$ is a rabbit in $C$:\\
     $\valueof{\ol{rabbit}}^{\theta,C}(b) =\true$
    \item $r$ is in some $b$:\\
        $\valueof{\ol{in}}^{\theta,C}(r,b) =\true$, where:
        \begin{itemize}
          \item $b$ is a bag in $C$:\\
            $\valueof{\ol{bag}}^{\theta,C}(b) =\true$
          \item $b$ is bigger than the other bag in $C$:
          \begin{itemize}
            \item There is exactly one referent $b'\neq b$ such that $\valueof{\ol{bag}}^{\theta,C}(b') =\true$.
            \item \textsf{size}($b$) $>$ \textsf{size}($b'$)
          \end{itemize}
        \end{itemize}
\item No referent distinct from $r$ in $C$ meets conditions 1-2.
\end{enumerate}
The standard analysis of the definite article is also compatible with a low interpretation of the comparative, and this would merely add a uniqueness clause for the referent of the embedded description.

A high interpretation of the comparative necessitates a high interpretation of the definite article. On such an interpretation, \ol{the rabbit in the bigger bag} is true of $r$ if and only if:
%
\begin{enumerate}
  \item $r$ is a rabbit in $C$:\\
    $\valueof{\ol{rabbit}}^{\theta,C}(b) =\true$
  \item $r$ is in some $b$:\\
    $\valueof{\ol{in}}^{\theta,C}(r,b) =\true$ where:
    \begin{itemize}
      \item $b$ is a bag in $C$:\\
        $\valueof{\ol{bag}}^{\theta,C}(b) =\true$
      \item $b$ is bigger than the other rabbit-containing bag in $C$:
        \begin{itemize}
          \item There is exactly one referent $b'\neq b$ such that:
            \begin{itemize}
              \item $\valueof{\ol{bag}}^{\theta,C}(b') =\true$
              \item there is some $r'$ such that:
                \begin{itemize}
                  \item $\valueof{\ol{rabbit}}^{\theta,C}(r')$
                  \item $\valueof{\ol{in}}^{\theta,C}(r',b')$
                \end{itemize}
            \end{itemize}
            \item \textsf{size}($b$) $>$ \textsf{size}($b'$)
        \end{itemize}
      \end{itemize}
    \item No referent distinct from $r$ in $C$ meets conditions 1-2.
\end{enumerate}
On the high interpretation of the comparative, then, the comparison class consists of the set of rabbit-containing bags, rather than the full set of bags. No bag that does not contain a rabbit will have any impact on whether the description truthfully and felicitously applies to the referent.



\section{\label{computational-model}Computational Model}

We implement an RSA model where the pragmatic listener jointly infers a referent, a threshold and a context. Our model includes Context Coordination (CC), which allows the context to be narrowed down in order to accomodate the semantic requirements of the speaker's utterance.


\subsection{Literal Listener}

The Literal Listener infers a referent $r$ given a description $d$, a context $C$ and a threshold $\theta$ proportionally to 1) whether the description is true of $r$ in $C$ given the threshold value; and 2) the prior probability of $r$.
%The threshold $\theta$ is used in the interpretation of the relative adjective {\em big} and its comparative form {\em bigger} (see semantics in the previous section). 
In other words, the literal listener discards referents that do not satisfy the semantic requirements of the description, and assigns a posterior probability to any remaining referent as a function of the referent's prior probability (\ref{literal-listener}).

\begin{equation}
  L_0(r\given d,C,\theta) \propto \llbracket d \rrbracket^{C,\theta}(r)\cdot P(r) 
  \label{literal-listener}
\end{equation}


In this model, both $\theta$ and $C$ are treated as lifted variables, i.e., their value is not resolved at the level of the model where they are first called (i.e., at the Literal Listener level).
Rather these variables are `lifted' all the way up to the Pragmatic Listener, where its value is resolved.
%I don't understand this paragraph --Liz

The posterior distribution in (\ref{literal-listener}) is undefinable if the existence and/or uniqueness presuppositions associated with the definite determiner are not satisfied, i.e., if $C$ does not contain exactly one referent $r$ that satisfies the description $d$ for the adjectival threshold $\theta$.
Presupposition failure is technically implemented by positing a special \textsf{fail} referent, with prior probability $\epsilon$. 
Otherwise, we assume an uninformative prior over referents, as shown in (\ref{undefined}).


\begin{equation} 
  P(r) =
    \begin{cases}
      \epsilon & \text{if } r = \textsf{fail}\\
      \text{uniform} & \text{otherwise} 
      \label{undefined}
    \end{cases}
\end{equation}

As discussed above, the same string can be assigned two different underlying structures (Logical Forms, as it were). 
For the comparative, in particular, Bumford's theory allows either a high or low scope construal.
The choice of construal is determined by a free parameter in the model, set to `r highScopeConstrualProb`.
%Why isn't this inline code showing up?
The higher this probability, the more likely the `bag' construal.

\subsection{Speaker}
The speaker is modeled as a {\em softMax} agent that chooses a description $d$, given that she wants to convey the referent $r$ in context $C$ for the adjectival threshold $\theta$.
In choosing utterances, the speaker balances out two constraints: maximizing the likelihood that the Literal Listener will infer the intended referent by choosing informative utterances, while minimizing production cost. 
Informativity is modeled as negative surprisal (or positive log probability) of the referent in the posterior, whereas utterance cost $C(u)$, is directly proportional to the utterance length.\footnote{Currently, the costs are set as follows: comparative 1.5; positive 1; and 0.5 if the utterance does not contain an adjective. 
%Should we talk about costCoefficient here?
} 
Finally, we assume a rationality parameter $\alpha$ of 1. 


\begin{equation} 
  S_1(d\given r,C,\theta) \propto \text{exp}(\alpha \times \text{ln}(L_0(r\given d,C,\theta)) -    \textsf{cost}(d)) 
  \label{speaker}
\end{equation} 



\noindent
\textbf{Questions to consider or to keep in mind:} \\
\noindent
1. Posterior probabilities go down if we have both pos and comparative alternative utterances compete with each other (see model results in section 4.4.). \\
\textbf{Actually it seems that the probabilities were going down because of the way that theta was being computed: whether or not we assume that uninformative thetas are categorically excluded. --Liz}\\
\noindent
2. We currently do not use a \emph{silence} utterance among the alternatives.\\


\subsection{Pragmatic Listener}

The Pragmatic Listener is modeled as a Bayesian agent that assigns posterior probabilities to referents $r$ given a masked description $d$, proportionally to the probability of the speaker using (any possible resolution of) $d$ to describe $r$ given context $C$ and assuming threshold $\theta$ (i.e., the likelihood), times the prior over referents given the context, the prior over thresholds given the context and a full description, and the prior over contexts (see equation \ref{pragmatic-listener}).


\begin{equation}
  \begin{array}{l}
    L_1(r\given d=N_1\textnormal{ in the (Adj) }\textsf{[masked]}) \propto \\
    \sum_C \sum_\theta \sum_{N_2} S_1(d=N_1\textnormal{ in the (Adj) }N_2\given r,C,\theta)\cdot P(r\given C)\cdot P                (\theta\given C,d)\cdot P(C)
  \end{array}
  \label{pragmatic-listener}
\end{equation}

For models without context coordination, the context $C$ always consists of the five referents present in the display ($C = \{r_1,r_2,r_3,r_4,r_5\}$).
In models that allow for Context Coordination, a context is any $C'$ such that $C'$ is in the powerset of $C$ ($C' \subseteq \mathcal{P}(C)$).

As seen in equation \ref{pragmatic-listener}, different types of priors modulate the probability of a given referent in the posterior; 
the prior probability of a referent $r$ given a context $C$ is uniform among the referents in the context and undefined otherwise. 
In the latter case, the referent receives a small but non-negligible probability $\epsilon$. 
Crucially, this value is fixed in models that do not use context coordination, but will vary in models that assume context coordination as a function of the context-referent pair under consideration. 

\begin{equation}
  P(r\given C) =
    \begin{cases}
      \epsilon & \text{if } r = \textsf{fail}\\
      \text{uniform among any } r \in C & \text{otherwise}
      \label{prior-referent-given-context}
    \end{cases}
\end{equation}

\textbf{The model results currently (November 4th) are derived using the assumption that the threshold categorically cannot be below the smallest. We are doing this because it seems to be the only way to get a preference for the bag overall; otherwise too much probability mass gets eaten up by non-targets (the smaller bag in particular, which has a rabbit in it). So the below is not accurate. --Liz}

The prior over thresholds is also assumed to be uniform among the possible threshold values licensed by the context and the description. 
Possible threshold values are obtained by extracting the referents in the context that are in the extension of the nested noun (e.g., bag), which is taken to provide the Comparison Class against which the adjective is evaluated ([reference]).
This prior derives the dispreference for the bag resolution in conditions that contain more than two bags (i.e., Contexts 1 and 3), even if the biggest bag in the display does not contain an animal that matches the first noun in the description.\footnote{There's something funny about this logic. If Context 1 contained frogs in the two biggest bags, and a rabbit in the smallest bag, it would be off to refer to that referent as the rabbit in the big bag. I think our model does not predict a dispreference agianst this. Both big and small would be equally preferred here. Also, doesn't this logic predict that if we were comparing Context 1 to another context where the frog in the biggest bag is substituted by a rabbit, we would still get lower probability for the bag resolution compared to the box resolution? Is this right?} 
In such contexts, the prior probability of each of the thresholds licensed by the description and the context will be lower than the condition that only contains two bags (Context 2), since the prior probability is split among three possible thresholds, as opposed to two, as exemplified in Figure \ref{thres-fig}. Each threshold receives higher probability in the prior in context 2 compared to contexts 1 and 3.
This difference in the prior over threshold values results in higher posterior probabilities for the bag resolution compared to the box resolution, since the number of boxes in any given context is never greater than two.



\begin{figure}
\centering
  \begin{minipage}[c]{0.45\textwidth}
    \includegraphics[width=3.0in]{images/con1.png}
    %\caption{Possible thresholds for the positive form adjective {\em big} in a context     including two bags.}
    \label{2bag-context}
  \end{minipage}
  \begin{minipage}[c]{0.45\textwidth}
    \includegraphics[width=3.0in]{images/con2.png}
    %\caption{Possible thresholds for the positive form adjective {\em big} in a context     including three bags.}
    \label{3bag-context}
  \end{minipage}
  \label{thres-fig}
  \caption{Possible thresholds for the positive form adjective {\em big} in contexts     including two (left pannel) and three (right pannel) bags.}
\end{figure}

Finally, the last term in equation \ref{pragmatic-listener} corresponds to the prior over contexts.
In models that do not invoke Context Coordination, there is only one context considered by the listener, and so the prior probability of this context is 1.
For models that do involve Context Coordination, the prior probability over contexts (i.e., any element in the powerset of the set containing all referents) is determined by 
%the distribution resulting from the exponential function in \ref{context-prior}. 
a parameter $\gamma$.
For each referent, a coin weighted $\gamma$ is flipped in order to determine whether or not the referent is included in the context.
The higher $\gamma$ is, the greater the preference for larger contexts.
The resulting probability distribution is renormalized to exclude the empty context;
this ensures that the probability distribution over referents is well-defined.
%I got the error "All paths explored by Enumerate have probability zero" when I did not do this, but I don't know why --Liz

%This distribution is supported for the values corresponding to the cardinalities of the possible contexts. 
%When the parameter $\gamma = 1$, the resulting prior over contexts is the uninformative prior. 
%When the parameter is set $\gamma > 1$, the result is a skewed prior that places higher prior probability on contexts of bigger cardinalities.

%Finally, the last term in equation \ref{pragmatic-listener} samples contexts from a $beta$ prior with parameters $\alpha=2$ and $\beta =1$ that assigns higher probability to bigger contexts as shown in XX. [\textbf{This needs to be completed}]

% \begin{equation}
% \begin{multlined}
%   f(C) =  \frac{1}{Z}2^{\gamma \mid C\mid}\text{, where }Z =\sum_{C \in \mathcal{P}(C)}2^{\gamma\mid C\mid}\text{    , such that} \\
%   P(C) =
%   \begin{cases}
%     \text{Uniform for } \gamma = 0\\
%     \text{For } \gamma > 0\text{: Bigger contexts receive higher probability in the prior.}
%   \end{cases}
% \end{multlined}
%   \label{context-prior}
% \end{equation}


\noindent
\textbf{Open questions}:\\
\noindent
1. The discussion on threshold values is missing treatment of thresholds for the comparative.\\
\textbf{Good, because the comparative is not threshold-sensitive --Liz}\\
\noindent
2. As of now, skewness is only in context prior. Do we also want to use a skewed prior as part of the referents given context probability?\\
\textbf{Is this moot, now that we have implemented Roger's $\gamma$? --Liz}\\

% \begin{verbatim}
% var referentsPriorGivenContext = function(context) {
%   return Infer({method: "enumerate"}, function() {
%      flip(0.01) ? rU : uniformDraw(context)
%   });
% };
% \end{verbatim}

\noindent
3. Alternative ways of implementing skewedness?\\
\textbf{Is this done? --Liz}\\



\subsection{Simulations}

Simulation results for the model described in Section \ref{computational-model}.\\

\begin{figure}[h]
\centering
<<Plot-standard, echo=FALSE, cache=TRUE, warning=FALSE, message=FALSE, fig.width = 6, fig.height=3.5>>=

## Plots ##

bags.standard<-subset(results, Container=="bag" & DefArtMeaning=="standard" & Model=="haddock_model.wppl")


cbPalette <- c("#009E73", "#CC79A7","#E69F00", "#56B4E9",  "#F0E442", "#0072B2", "#D55E00",  "#999999")

standard<-ggplot(bags.standard, aes(x=Condition, y=Probability, fill=Adjective)) + 
  geom_bar(position=position_dodge(), stat="identity") +
  scale_fill_manual(values=cbPalette) +
  theme_bw() +
  theme(axis.text.x = element_text(size=8),
        axis.text.y = element_text(size=15),  
        axis.title.x = element_text(size=18),
        axis.title.y = element_text(size=18),
        legend.title=element_text(size=16), 
        legend.text=element_text(size=14)
  ) +
  ylim(0,1) +
  xlab("Display Type") +
  ylab("Bag Resolution") +
  ggtitle("Standard Meaning") +
  facet_grid(Context ~ Adjective) +
  labs(fill="Adj. Type")

standard
@
\caption{Simulation results for model using standard meaning.}
\end{figure}

\noindent
\textbf{Open Questions:} I do not understand the comparative results with standard meaning. Why are Contexts 1 and 2 not the same? This needs to be further investigated.\\
\textbf{With Context 1, there are potentially three bags, depending on how the context is set. This presents a risk that the comparative will be undefined. The comparative requires there to be two bags. --Liz}

\begin{figure}[!htbp]
\centering
<<Plot-bumford, echo=FALSE, cache=TRUE, warning=FALSE, message=FALSE, fig.width = 6, fig.height=3.5>>=

## Plots ##
bags.bumford<-subset(results, Container=="bag" & DefArtMeaning=="bumford" & Model=="haddock_model.wppl")

bumford<-ggplot(bags.bumford, aes(x=Condition, y=Probability, fill=Adjective)) + 
  geom_bar(position=position_dodge(), stat="identity") +
  scale_fill_manual(values=cbPalette) +
  theme_bw() +
  theme(axis.text.x = element_text(size=8),
        axis.text.y = element_text(size=15),  
        axis.title.x = element_text(size=18),
        axis.title.y = element_text(size=18),
        legend.title=element_text(size=16), 
        legend.text=element_text(size=14)
  ) +
  ylim(0,1) +
  xlab("Display Type") +
  ylab("Bag Resolution") +
  ggtitle("Bumford's Meaning") +
  facet_grid(Context ~ Adjective) +
  labs(fill="Adj. Type")

bumford
#ggarrange(standard, bumford + rremove("x.text"), 
#          heights = c(2, 2.5),
 #         ncol = 1, nrow = 2)
@
\caption{Simulation results for model using Bumford's meaning.}
\end{figure}


\pagebreak 

\bibliography{master}
\bibliographystyle{sp}

\appendix
 

\section{Why comparatives have both absolute and relative readings}


As with superlatives \citep[i.a.]{szabolcsi:1986,coppock+beaver:salt2014}, 
relative readings of comparatives obviate definiteness effects:

\begin{exe}
\ex
\begin{xlist}
\ex *Bernie has the campaign chairman.
\ex Bernie has the most enthusiastic campaign chairman.
\ex Bernie has the more enthusiastic campaign chairman.
\end{xlist}
\end{exe}


As \citet{bumford:2017} discusses, 
relative readings blocked by possessives, 
both for superlatives and for comparatives:

\begin{exe}
\ex
\begin{xlist}
\ex Who has read the longest play by Shakespeare?
\ex Who has read Shakespeare's longest play?
\end{xlist}
$\equiv$ Who has read Hamlet?
\end{exe}

\begin{exe}
\ex
\begin{xlist}
\ex Who has read the longer play by Shakespeare?
\ex Who has read Shakespeare's longer play?
\end{xlist}
$\leadsto$ Shakespeare wrote two plays?
\end{exe}


Further evidence comes from ambiguities of the following type,
observed by \citet{bhatt:2002} for \ref{tolstoy:first} and
\ref{tolstoy:longest}.
\ref{tolstoy:longer} is ambiguous in an analogous way.

\begin{exe}
\ex
\begin{xlist}
\ex the first book that John said Tolstoy had written\label{tolstoy:first}
%\b. the only book that John said Tolstoy had written
\ex the longest book that John said Tolstoy had written\label{tolstoy:longest}
\ex the longer book that John said Tolstoy had written\label{tolstoy:longer}
\end{xlist}
High reading: of the books John said Tolstoy
wrote, the longer\\
Low reading: the book John said was longer among Tolstoy's.
\end{exe}


\citet{sleeman:2010}: `identificational focus' \citep{kiss:1998a}

As with superlatives \citep{bhatt:1999,bhatt:2006},
relative readings of comparatives are blocked by non-modal infinitival relative clauses:

\begin{exe}
\ex
\begin{xlist}
\ex John gave Mary the most expensive telescope
\ex ... to be built in the
9th century.
\end{xlist}
\end{exe}


\begin{exe}
\ex
\begin{xlist}
\ex John gave Mary the more expensive telescope
\ex ... to be built in the
9th century.
\end{xlist}
\end{exe}


\newpage
\section{Pragmatic Listener 2}

\noindent
Below we present a model that includes another level of recursion, i.e. Pragmatic Speaker 2. The details of the model below do not include the literal listener and level 1 speaker.\\

\noindent
\textbf{Pragmatic Listener}

\begin{equation} 
  L_1(r\given d) \propto \sum_C \sum_\theta S_1(d\given r,C,\theta) \cdot P(r\given C)\cdot P(\theta\given C,d)\cdot P(C)
  \label{l1-full}
\end{equation} 

\noindent
\textbf{Pragmatic Speaker}
\begin{equation} 
  S_2(u\given r) \propto    \text{exp}(\alpha \times \text{ln} (L_1(r\given d) ) -    \textsf{cost}(d)) 
  \label{pragmatic-speaker}
\end{equation} 

\noindent
\textbf{Second Level Pragmatic Listener (L2)}
\begin{equation} 
  L_2(r\given d=N_1\textnormal{ in the (Adj) }\textsf{[masked]}) \propto  \sum_{N_2}S_2(u\given r) \cdot P(r)
  \label{s2-pragmatic-listener}
\end{equation} 


\subsection{Sumulation Results for Pragmatic Listener 2 Models}

\begin{figure}[h]
\centering
<<Plot-standard-pragList2, echo=FALSE, cache=TRUE, warning=FALSE, message=FALSE, fig.width = 6, fig.height=3.5>>=

## Plots ##

bags.standard.pragList2<-subset(results, Container=="bag" & DefArtMeaning=="standard" & Model=="haddock_model_pragmaticListener2.wppl")


cbPalette <- c("#009E73", "#CC79A7","#E69F00", "#56B4E9",  "#F0E442", "#0072B2", "#D55E00",  "#999999")

standard.pragList2<-ggplot(bags.standard.pragList2, aes(x=Condition, y=Probability, fill=Adjective)) + 
  geom_bar(position=position_dodge(), stat="identity") +
  scale_fill_manual(values=cbPalette) +
  theme_bw() +
  theme(axis.text.x = element_text(size=8),
        axis.text.y = element_text(size=15),  
        axis.title.x = element_text(size=18),
        axis.title.y = element_text(size=18),
        legend.title=element_text(size=16), 
        legend.text=element_text(size=14)
  ) +
  ylim(0,1) +
  xlab("Display Type") +
  ylab("Bag Resolution") +
  ggtitle("Standard Meaning") +
  facet_grid(Context ~ Adjective) +
  labs(fill="Adj. Type")

standard.pragList2
@
\caption{Simulation results for Model using standard meaning and a second level of embedding (Pragmatic Listener 2)}
\end{figure}


\begin{figure}[h]
\centering
<<Plot-bumford-pragList2, echo=FALSE, cache=TRUE, warning=FALSE, message=FALSE, fig.width = 6, fig.height=3.5>>=

## Plots ##
bags.bumford.pragList2<-subset(results, Container=="bag" & DefArtMeaning=="bumford" & Model=="haddock_model_pragmaticListener2.wppl")

bumford.pragList2<-ggplot(bags.bumford.pragList2, aes(x=Condition, y=Probability, fill=Adjective)) + 
  geom_bar(position=position_dodge(), stat="identity") +
  scale_fill_manual(values=cbPalette) +
  theme_bw() +
  theme(axis.text.x = element_text(size=8),
        axis.text.y = element_text(size=15),  
        axis.title.x = element_text(size=18),
        axis.title.y = element_text(size=18),
        legend.title=element_text(size=16), 
        legend.text=element_text(size=14)
  ) +
  ylim(0,1) +
  xlab("Display Type") +
  ylab("Bag Resolution") +
  ggtitle("Bumford's Meaning") +
  facet_grid(Context ~ Adjective) +
  labs(fill="Adj. Type")

bumford.pragList2
#ggarrange(standard, bumford + rremove("x.text"), 
#          heights = c(2, 2.5),
#          ncol = 1, nrow = 2)
@
\caption{Simulation results for Model using Bumford's meaning and a second level of embedding (Pragmatic Listener 2)}
\end{figure}


\textbf{Questions to consider or to keep in mind:} No inference over thresholds or contexts at L2? I have used a flat prior over contexts here. Something is off with the comparative. These models take a really long time to run!


\end{document}